{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## SVZ cheatsheet\n",
    "### marusja2 - 2024/2025"
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:31:18.570777Z",
     "start_time": "2025-01-19T16:31:18.455601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import improutils"
   ],
   "id": "2cd5fac4797c2615",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Dokumentace\n",
    "\n",
    "- help(funkce) - zobrazí nápovědu k funkci\n",
    "- [Improutils - FIT Gitlab](https://gitlab.fit.cvut.cz/bi-svz/improutils_package)\n",
    "- [Improutils - Github](https://github.com/ImprolabFIT/improutils)\n",
    "- [Improutils - Docs](https://improutils.readthedocs.io/en/master/)\n",
    "- [OpenCV](https://docs.opencv.org/4.x/)"
   ],
   "id": "7b378ec13eafff9d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Výběr snímací soustavy"
   ],
   "id": "c7e45d7dade697ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Výběr kamery\n",
    "\n",
    "| Parametr                    | jednotka | označení |\n",
    "|-----------------------------|----------|----------|\n",
    "| Rozlišení kamery v pixelech | px       | $r$      |\n",
    "| Maximální velikost objektu  | mm       | $w$      |\n",
    "| Přesnost (nejmenší rozdíl)  | mm       | $p$      |\n",
    "\n",
    "Potřeba zvolit takovou kameru, že platí:\n",
    "\n",
    "$$r \\geq \\frac{1.1 \\cdot w}{p / 2} = 2.2 \\frac{w}{p}$$\n",
    "\n",
    "- Hodnota $1.1$ v čitateli jako přesah zorného pole (5 % na každé straně)\n",
    "- Hodnota $2$ ve jmenovateli... alespoň dva pixely pro změnu kontrastu (jeden bílý, jeden černý)\n",
    "\n",
    "## Příklad\n",
    "\n",
    "Měření objektů 20 mm a menších, potřeba přesnost 0.01 mm.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "w = 20 \\text{\\ mm}, p = 0.01 \\text{\\ mm} \\ \\\n",
    "    r_{min} = 2.2 \\cdot \\frac{20}{0.01} = 2.2 \\cdot 2000 = 4400 \\text{\\ px}\n",
    "\\end{aligned}\n",
    "$$"
   ],
   "id": "715cc1cc8895ac9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Výběr objektivu\n",
    "\n",
    "Na základě parametrů úlohy $Y, L$ a vybrané kamery $Y'$:\n",
    "\n",
    "| Parametr                                      | jednotka | označení |\n",
    "|-----------------------------------------------|----------|----------|\n",
    "| Maximální velikost objektu                    | mm       | $Y$      |\n",
    "| Velikost obrazu (delší ze dvou stran)         | mm       | $Y'$     |\n",
    "| Pracovní vzdálenost (objekt-povrch objektivu) | mm       | $L$      |\n",
    "| Ohnisková vzdálenost objektivu                | mm       | $f$      |\n",
    "\n",
    "Potřeba zvolit takový objektiv, že platí:\n",
    "\n",
    "$$f = Y' \\cdot \\frac{L}{1.1 \\cdot Y}$$\n",
    "\n",
    "Pokud máme možnou vzdálenost v rozsahu $[L_\\min, L_\\max]$, potom:\n",
    "\n",
    "$$Y' \\cdot \\frac{L_\\min}{1.1 \\cdot Y} \\leq f \\leq Y' \\cdot \\frac{L_\\max}{1.1 \\cdot Y}$$\n",
    "\n",
    "Hodnota $1.1$ ve jmenovateli jako přesah zorného pole (5 % na každé straně)\n",
    "\n",
    "## Příklad\n",
    "\n",
    "Měření objektů 200 mm a menších, kamera musí být umístěna ve vzdálenosti $[400, 600] \\text{\\ mm}$. Zvolená kamera má snímací čip o velisosti $7.2 \\times 5.4 \\text{\\ mm}$.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Y = 200 \\text{\\ mm}, Y' = 7.2 \\text{\\ mm}, L \\in [400, 600] \\text{\\ mm} \\\\\n",
    "f_\\min = Y' \\cdot \\frac{L_\\min}{1.1 \\cdot Y} = 7.2 \\cdot \\frac{400}{1.1 \\cdot 200} = 13.09 \\text{\\ mm} \\\\\n",
    "f_\\max = Y' \\cdot \\frac{L_\\max}{1.1 \\cdot Y} = 7.2 \\cdot \\frac{600}{1.1 \\cdot 200} = 19.64 \\text{\\ mm} \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Můžeme tedy zvolit např. objektiv s $f=16 \\text{\\ mm}$.\n",
    "\n",
    "V takovém případě zvolíme pracovní vzdálenost $L = f \\cdot \\frac{1.1 \\cdot Y}{Y'} = 488.8 \\text{\\ mm}$. Kamera ale bude umístěna dál, a to o délku objektivu!!! Treba jeste pricteme 28mm (dle specsheetu delky objektivu napr).\n",
    "\n",
    "Pokud i tak nerozhodnome objektiv, tak lze vybrat dle velikosti snimace. (vetsi nebo rovna a idealne blizko) 1/1.8\" apod."
   ],
   "id": "bb5696e9f9dc702"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T10:09:47.683001Z",
     "start_time": "2025-01-21T10:09:47.674353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def diag_inch_to_mm(inch):\n",
    "    # senzor 1\" = 16mm - kvůli tomu, že je to velikost diagonály a my počítáme velikost strany (inch je 25.4mm)\n",
    "    return inch * 16\n",
    "\n",
    "def diag_mm_to_inch(mm):\n",
    "    return mm / 16.0\n",
    "\n",
    "def get_min_camera_size(obj_size, precision):\n",
    "    # Maximální velikost objektu (obj_size) v mm (delší strana), přesnost (accuracy) v mm\n",
    "    # Výsledek je požadované rozlišení kamery v pixelech,\n",
    "\n",
    "    res = (obj_size * 1.1) / (precision / 2)\n",
    "    return res\n",
    "\n",
    "def get_real_camera_res_prec(camera_res, obj_size):\n",
    "    # Vrací skutečnou hodnotu rozlišení, mm/px a skutečnou hodnotu přesnosti v mm\n",
    "    obj_size_adjus = obj_size * 1.1\n",
    "    real_res = obj_size_adjus / camera_res\n",
    "    real_precision = real_res * 2\n",
    "    return real_res, real_precision\n",
    "def get_focal_length(obj_size, sensor_size, working_dist):\n",
    "    # Maximální velikost objektu v mm, velikost snímače (sensor_size) v mm, pracovní vzdálenost v mm (objekt-povrch objektivu)\n",
    "    # Výsledek je požadovaná ohnisková vzdálenost objektivu (značení f - focal point)\n",
    "\n",
    "    f = sensor_size * working_dist * (1 / (1.1 * obj_size))\n",
    "    return f\n",
    "\n",
    "\n",
    "def get_adjusted_focal_length(f_lens, obj_size, sensor_size, midlens_size):\n",
    "    # Ohnisková vzdálenost v mm, velikost objektu v mm, velikost obrazu v mm, velikost objektivu v mm\n",
    "    # Vrací skutečnou pracovní vzdálenost\n",
    "\n",
    "    res = f_lens * 1.1 * obj_size / sensor_size\n",
    "    res += midlens_size\n",
    "    return res\n",
    "\n",
    "def calculation():\n",
    "    obj_size = 200\n",
    "    precision = 0.3\n",
    "    print(f\"Velikost objektu: {obj_size} mm, přesnost: {precision} mm\\n\")\n",
    "    min_size = get_min_camera_size(obj_size, precision)\n",
    "    print(f\"Minimální rozlišení kamery: {min_size:.3f} px\")\n",
    "    real_picked_cam_res = 1626 # px\n",
    "    print(f\"Zvolené rozlišení kamery: {real_picked_cam_res} px\")\n",
    "    real = get_real_camera_res_prec(real_picked_cam_res,obj_size)\n",
    "    print(f\"Skutečné rozlišení kamery: {real[0]:.3f} mm*px^-1, přesnost: {real[1]:.3f} mm\")\n",
    "    print(\"Zvolená kamera: TODO vypsat parametry ze specsheetu\")\n",
    "    print()\n",
    "\n",
    "    min_working_distance = 400\n",
    "    max_working_distance = 600\n",
    "    mid_working_distance = (min_working_distance+max_working_distance)/2\n",
    "    real_picked_cam_sensor = 7.2 # 7.2 x 5.4 mm\n",
    "    lens_length_real = 28.2 # specsheet (mm)\n",
    "    print(f\"Pracovní vzdálenost: {min_working_distance} - {max_working_distance} mm\")\n",
    "    focal_mm = get_focal_length(obj_size,real_picked_cam_sensor, mid_working_distance)\n",
    "    focal = diag_mm_to_inch(focal_mm)\n",
    "    print(f\"Zvolená ohnisková vzdálenost: {focal_mm:.3f} mm, {focal:.3f} inch\")\n",
    "    real_picked_focal_mm = 16 # specsheet (mm)\n",
    "    adj_focal = get_adjusted_focal_length(real_picked_focal_mm, obj_size, real_picked_cam_sensor, lens_length_real)\n",
    "    print(f\"Skutečná pracovní vzdálenost: {adj_focal:.3f} mm\")\n",
    "    print(\"Zvolený objektiv: TODO vypsat parametry ze specsheetu\")"
   ],
   "id": "80f69442616c5b25",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Nastavení snímací soustavy\n",
    "- kamera - rozlišení, barevný rozsah (RGB,mono), velikost senzoru\n",
    "- objektiv - ohnisková vzdálenost, rozsah clony, velikost objektivu (větší nebo rovna velikosti senzoru), rozsah ostření\n",
    "- světla"
   ],
   "id": "2f0569a152af97b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Vyvazeni bile, gain, clona, expozicni cas, ostrost,fps (acquisition frame v pylon), pokud barevne tak histogram.\n",
    "\n",
    "Pracovní vzdálenost (okraj objektivu - povrch objektu)\n",
    "- vs. minimální pracovní vzdálenost objektivu\n",
    "\n",
    "Kamera\n",
    "- rozlišení obrázku (před ořezem)\n",
    "- -> poměr stran\n",
    "- barevný rozsah (černobílá/RGB, počet bitů na barvu)\n",
    "- video... framerate (snímkovací frekvence)\n",
    "- fyzická velikost senzoru (např. `1/1.8\"`, 1\" = 16 mm, měřeno na diagonále)\n",
    "- -> velikost pixelu, mm/px; **přesnost** = dvojnásobek velikosti pixelu\n",
    "\n",
    "Objektiv\n",
    "- ohnisková vzdálenost (např. `f = 8 mm`, v průmyslu většinou pevná)\n",
    "- rozsah clony (např. `F 1.4 - 16.0`), podíl ohniskové vzdálenosti a průměru otvoru clony\n",
    "- fyzická velikost objektivu (např. `1/1.8\"` nebo `7,2 x 5,4 mm`), **větší nebo rovna velikosti senzoru**\n",
    "\n",
    "Nasvícení\n",
    "- Směrové... soustředí se přímo na objekt, rovnoběžné paprsky\n",
    "    - nereflexivní povrchy\n",
    "    - **zvýraznění reliéfu**\n",
    "- Difúzní/rozptýlené světlo... nepřímé\n",
    "    - lesklé povrchy\n",
    "    - často jako diuzor přes klasické (přímé) světlo\n",
    "    - **skrytí reliéfu**\n",
    "- Zadní... použití pro maximální **zvýraznění obrysu**\n",
    "    - se silným difuzorem\n",
    "    - Nejčastěji se používá ke zjišťování přítomnosti/nepřítomnosti otvorů/mezer, ke zjištění orientace objektů, či k jejich měření\n",
    "- Dark Field... velké množství LED diod okolo objektu, svítí pod ostrým bočním úhlem\n",
    "    - **velké zvýraznění reliéfu**, vyrytých/vytlačených nápisů atd.\n",
    "- Kopulové... Opak dark fieldu, světlo přichází ze všech stran, rovnoměrně\n",
    "    - **maximální skrytí reliéfu**\n",
    "- *Koaxiální*... díky propustnému zrcadlu světlo ze stejného směru, jako kamera\n",
    "    - DOAL = Diffused On Axis Light\n",
    "    - elimance odlesků, zvýraznění detailů"
   ],
   "id": "257b1ca03fd87824"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Vinětace\n",
    "tmavé rohy obrázku, do rohů senzoru nedopadá dostatek světla (oproti středu)\n",
    "\n",
    "Příčiny:\n",
    "- konstrukce objektivu (příliš úzký)\n",
    "- příliš **otevřená** clona\n",
    "\n",
    "Řešení:\n",
    "- vyměnit objektiv za širší\n",
    "- uzavřít clonu\n",
    "\n",
    "### Chromatická aberace\n",
    "barevné lemování hran\n",
    "\n",
    "Příčiny:\n",
    "- konstrukce čočky objektivu\n",
    "- příliš **otevřená** clona\n",
    "\n",
    "Řešení:\n",
    "- vyměnit objektiv (jiný materiál čočky, menší zoom)\n",
    "- uzavřít clonu\n",
    "\n",
    "### Difrakce\n",
    "snížení ostrosti obrazu, zrnitost\n",
    "- obecný problém průchodu vlnění úzkou štěrbinou\n",
    "- [Difrakce (Wikipedia)](https://cs.wikipedia.org/wiki/Difrakce)\n",
    "\n",
    "Příčiny:\n",
    "- příliš **uzavřená** clona\n",
    "\n",
    "Řešení:\n",
    "- nastavit clonu na **sweet-spot** (omezení všech vad optiky)\n",
    "\n",
    "### Distorze\n",
    "Zakřivení čar, které jsou v realitě rovné\n",
    "- zejména u **širokoúhlých objektivů**\n",
    "- **radiální** distorze... barrel/pincushion\n",
    "- **tangenciální**... \"naklonění\" obrazu, jedna strana blíže než druhá\n",
    "\n",
    "Řešení:\n",
    "- výměna objektivu\n",
    "- digitální **kalibrace** obrazu\n",
    "\n",
    "Kalibrace:\n",
    "- na základě snímků referenčního obrazu (šachovnice známých rozměrů)\n",
    "- ztrátová... odříznutí zakřiveného obrazu v krajích\n",
    "- formálně... nalezení kalibračních parametrů\n",
    "- $k_{1:3}$ pro radiální\n",
    "- $p_{1:2}$ pro tangenciální"
   ],
   "id": "2ee8529d3603460c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Kalibrace kamery\n",
    "- Nafotit 10-20 fotek šachovnice z různých úhlů a v různých částech obrazu.\n",
    "- Zkalibrovat."
   ],
   "id": "d6de762367b69a55"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Bacha na odlesky\n",
    "- Velikost šachovnice: Velikost šachovnice by měla být zvolena tak, aby při požadované pracovní vzdálenosti zabírala alespoň 50% snímku při pohledu, kdy je šachovnice paralelně se snímačem (fronto-paralelně).\n",
    "- Natočení vzoru: Pro zjištění distorzních parametrů by měly postačit pouze fronto-paralelní snímky šachovnice. Pro zjištění vnitřních parametrů je zapotřebí vzor natáčet v různých úhlech. Doporučené natočení je +- 45° okolo vertikální a horizontální osy. I v případě, že chceme zjistit pouze distorzní parametry, je vhodné natáčet vzor v různých úhlech a vytvořit větší dataset.\n",
    "- Rozložení snímků: Musíme vzor umístit do všech částí snímku. Pokud nebudeme mít např. vzor na okrajích, parametry nebudou dostatečně svázány (constrained).\n",
    "- Filtrace snímků: Po samotné kalibrací je vhodné provést filtraci snímků. Často nekvalitní snímky mohou zhoršit výsledky kalibrace a jejich reproječní chyba je vyšší než u ostatních snímků. Následně je možné pořídit snímek znovu a opětovně provést kalibraci.\n",
    "- Overfitting: Nízká reprojekční chyba neznamená nutně dobrou kalibraci. Může se jednat o přeučení (overfitting) modelu na daný dataset. Nastává při použití příliš flexibilního modelu."
   ],
   "id": "65160b34bffb719c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:31:20.511904Z",
     "start_time": "2025-01-19T16:31:18.583712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from improutils import create_file_path, reindex_image_files, camera_calib\n",
    "import yaml\n",
    "\n",
    "def calib1():\n",
    "    calib_folder_path = \"data/calibration\"\n",
    "\n",
    "    reindex_image_files(calib_folder_path)\n",
    "    images_format = '%01d.bmp'\n",
    "\n",
    "    calibration_file_name = \"calibration.yaml\" ### *.yaml\n",
    "    output_calib_file_path = create_file_path(calib_folder_path, calibration_file_name)\n",
    "\n",
    "    chess_shape = (9, 6)  # počet rohů mezi čtverci šachovnice, ignoruje jednu řadu čtverců od každého kraje\n",
    "\n",
    "    input_source = create_file_path(calib_folder_path, images_format)\n",
    "    camera_matrix, dist_coefs, good_images = camera_calib(input_source=input_source, chess_shape=chess_shape,output_calib_file=output_calib_file_path) ###"
   ],
   "id": "1a01591523c6ee1f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "from improutils import plot_images\n",
    "\n",
    "def calib2():\n",
    "    chess_shape = (9,6) ### tuple\n",
    "    calib_folder_path = './calib_photos' ###\n",
    "    reprojection_error, camera_matrix, dist_coeffs, _, _, std_deviations_intrinsics, _, per_view_errors, chessboard_images = camera_calibration(calib_folder_path, chess_shape) ###\n",
    "\n",
    "    detected_images = list(chessboard_images.values())\n",
    "    plot_images(*detected_images[0:]) ###\n",
    "\n",
    "    detected_image_names = list(chessboard_images.keys())\n",
    "    pixel_size = 0.00000586 ### use cameras datasheet to find pixel size\n",
    "    calibration_stats(reprojection_error, camera_matrix, dist_coeffs, std_deviations_intrinsics, per_view_errors, detected_image_names, pixel_size) ###\n",
    "\n",
    "    img_corrected = correct_frame(img_distorsion, camera_matrix, dist_coeffs) ###\n",
    "\n",
    "    plot_images(img_distorsion, img_corrected) ###"
   ],
   "id": "e60ea3a5cd7f763c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:31:20.549932Z",
     "start_time": "2025-01-19T16:31:20.547990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def correct_frame(frame, camera_matrix, dist_coeffs):\n",
    "    \"\"\"Returns undistorted frame.\"\"\"\n",
    "    return cv2.undistort(frame, camera_matrix, dist_coeffs)"
   ],
   "id": "68cb5fcfde44c5df",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Měření dílu\n",
    "- Nafotit díl (s referenčním objektem)\n",
    "- Změřit díl"
   ],
   "id": "8e486d26203e3ae9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "Relevatntní funkce:\n",
    "- `segmentation_two_thresholds`\n",
    "- `segmentation_auto_threshold`\n",
    "- `segmentation_adaptive_threshold`\n",
    "- `segmentation_auto_threshold`\n",
    "\n",
    "Hledání kontury:\n",
    "- `cv2.dilate` [doc](https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html)\n",
    "- `cv2.erode`\n",
    "- `fill_holes`\n",
    "- `find_contours` -> `(contour_drawn: np.ndarray, count: int, contours: list)`\n",
    "\n",
    "`enum_contours` (hw01) !\n",
    "\n",
    "Převod na geometrický útvar:\n",
    "- `cv2.minAreaRect` -> `(center(x, y), (width, height), angle of rotation)` [guide](https://theailearner.com/tag/cv2-minarearect/)\n",
    "- `cv2.boundingRect` kolmý na osy x, y\n",
    "- `cv2.minEnclosingCircle` -> `(center, radius)`"
   ],
   "id": "a8ca3815353b7e9e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:31:20.581853Z",
     "start_time": "2025-01-19T16:31:20.554698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import improutils\n",
    "from improutils import apply_mask\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual  # slidery na segmentaci\n",
    "\n",
    "def slider():\n",
    "    # Grayscale/na jedné barvě\n",
    "    img = load_image('images/basic.png')\n",
    "    @interact(threshold_range=create_slider(min=0, max=255, description='Threshold range:',))\n",
    "    def _(threshold_range):\n",
    "        mask = improutils.segmentation_two_thresholds(img, threshold_range[0], threshold_range[1])\n",
    "        plot_images(mask)\n",
    "    # HSV\n",
    "    @interact(h_range=create_slider(min=0, max=360, description='Hue:'),\n",
    "              s_range=create_slider(min=0, max=255, description='Saturation:'),\n",
    "              v_range=create_slider(min=0, max=255, description='Value:'))\n",
    "    def _(h_range, s_range, v_range):\n",
    "\n",
    "        lower_bound = (improutils.to_intensity(h_range[0]), s_range[0], v_range[0])\n",
    "        upper_bound = (improutils.to_intensity(h_range[1]), s_range[1], v_range[1])\n",
    "\n",
    "        mask = improutils.segmentation_two_thresholds(img, lower_bound, upper_bound)\n",
    "        plot_images(mask, apply_mask(img, mask))"
   ],
   "id": "34eb9a5963f38d75",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Freestyle"
   ],
   "id": "cb5aae0c846c6324"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### General\n",
    "#### Popisné charakteristiky\n",
    "def form_factor(contour):\n",
    "def roundness(contour):\n",
    "def aspect_ratio(contour):\n",
    "def convexity(contour):\n",
    "def solidity(contour):\n",
    "def compactness(contour):\n",
    "def extent(contour):\n",
    "\n",
    "- Formfactor (špičatost)\n",
    "- Roundness (kulatost)\n",
    "- Aspect Ratio (poměr stran)\n",
    "- Convexity (konvexita, vypouklost)\n",
    "- Solidity (plnost, celistvost)\n",
    "- Compactness (kompaktnost, hutnost)\n",
    "- Extent (dosah, rozměrnost)\n"
   ],
   "id": "b9df7b28e6f64f45"
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "def segment_object(image, background):\n",
    "    image_negative = improutils.negative(image[...,2])\n",
    "    image_masked = improutils.apply_mask(image_negative, mask)\n",
    "    cont_drawn, _, contours = improutils.find_contours(apply_mask(neg, mask), 1000)\n",
    "    cont = contours[0]\n",
    "\n",
    "    binary_object_cropped = improutils.crop_by_bounding_rect(cont_drawn)\n",
    "\n",
    "    return binary_object_cropped, cont\n",
    "\n",
    "image = improutils.load_image(\"data/object.bmp\")\n",
    "background = improutils.load_image(\"data/background.bmp\")\n",
    "mask = improutils.segmentation_one_threshold(background[...,2], 128)  # red channel in BGR ... red backlight\n",
    "\n",
    "binary_object, cont = segment_object(image, mask)\n",
    "plot_images(binary_object)\n",
    "\n",
    "functions = [improutils.form_factor, improutils.roundness, improutils.aspect_ratio, improutils.convexity,\n",
    "            improutils.solidity, improutils.compactness, improutils.extent]\n",
    "\n",
    "shape_descriptions = list()\n",
    "\n",
    "for func in functions:\n",
    "    shape_descriptions.append(func(cont))\n",
    "\n",
    "# Konverze do np.array formátu\n",
    "shape_descriptions = np.array(shape_descriptions)"
   ],
   "id": "ea9e88aaa52b5272"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Some usage examples"
   ],
   "id": "491a704e0c997946"
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "# Aplikace Cannyho detektoru\n",
    "\n",
    "image_edges = cv2.blur(image, (3, 3))\n",
    "\n",
    "# Canny(image, threshold1, threshold2[, edges[, apertureSize[, L2gradient]]]) -> edges\n",
    "image_edges = cv2.Canny(image_edges, 200, 250)\n",
    "\n",
    "plot_images(image_edges)\n",
    "\n",
    "# Aplikace Houghovy transformace\n",
    "\n",
    "# HoughLinesP(image, rho, theta, threshold[, lines[, minLineLength[, maxLineGap]]]) -> lines\n",
    "linesP = cv2.HoughLinesP(image_edges, 1, np.pi / 2 - .025, 100, None, 300, 20)\n",
    "image_lines = draw_lines(image_edges, linesP)  # kreslení\n",
    "\n",
    "plot_images(image_lines)"
   ],
   "id": "f949aa0d93558d10"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Perspektiva"
   ],
   "id": "cc76c358d3dedc2a"
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "# nalezené z improutils.show_images\n",
    "src_pts = np.array([(47, 1013), (195, 128), (1316, 356), (1191, 1127)]) # np.array of tuples\n",
    "\n",
    "# A4 papír NA ŠÍŘKU... 210 x 297 mm\n",
    "dst_pts = np.array([(0, 2100), (0, 0), (2970, 0), (2970, 2100)]) # np.array of tuples\n",
    "\n",
    "H, mask = cv2.findHomography(src_pts, dst_pts)\n",
    "print(H, H.shape)\n",
    "\n",
    "warped_img = cv2.warpPerspective(img, H, (2970, 2100))  # překroutí celý obrázek\n",
    "plot_images(warped_img)\n",
    "\n",
    "point = np.array([[(346, 754)]], dtype='float32')  # bod z původního obrázku\n",
    "point_t = cv2.perspectiveTransform(point, H)  # překroutí jeden bod\n",
    "\n",
    "\n",
    "# moje pouziti v ukolu\n",
    "H, status = cv2.findHomography(temp_pts, orig_pts, cv2.RANSAC, 50.0)\n",
    "\n",
    "line_start = np.array([[(111,276)]], dtype='float32')\n",
    "line_end =  np.array([[(374,270)]], dtype='float32')\n",
    "\n",
    "line_start_t = cv2.perspectiveTransform(line_start,H )\n",
    "line_end_t = cv2.perspectiveTransform(line_end, H)\n",
    "\n",
    "dist = np.linalg.norm(line_start_t - line_end_t)\n",
    "print(f'Šířka v pixelech = {dist:.02f}')\n",
    "\n",
    "# 8.5cm délka Raspberry PI model 2 (model B)\n",
    "cm_per_pixel = 8.5/dist\n",
    "cm_per_pixel_sq = (cm_per_pixel**2)\n",
    "\n",
    "for i,cnt in enumerate(cnts):\n",
    "    area_pixels = cv2.contourArea(cnt)\n",
    "    area = area_pixels * cm_per_pixel_sq\n",
    "    print(f\"Plocha pro mikročip {i + 1}: {area:.2f} cm²\")"
   ],
   "id": "32630d630a4dd139"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Helper functions"
   ],
   "id": "d84fb12f3d7b9f5b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:31:20.591260Z",
     "start_time": "2025-01-19T16:31:20.588947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def describe_img(img: np.ndarray) -> None:\n",
    "    resolution = img.shape[:2] ###\n",
    "    print(f'Rozlišení obrazu:          {img.shape[:2] = }')\n",
    "\n",
    "    number_of_channels = img.shape[2] ###\n",
    "    print(f'Počet kanálů:              {img.shape[2] = }')\n",
    "\n",
    "    # np.min == np.amin != np.maximum\n",
    "    print(f'Nejnižší hodnota v obrazu: {np.min(img) = }')\n",
    "    print(f'Nevyšší hodnota v obrazu:  {np.max(img) = }')\n",
    "    print(f'Průměrná hodnota obrazu:   {np.mean(img) = }')\n",
    "\n",
    "    print(f'Rozlišení v MPix:          {resolution[0] * resolution[1] / (10 ** 6) = }')"
   ],
   "id": "cb165b7780f0dd95",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:31:20.597812Z",
     "start_time": "2025-01-19T16:31:20.595613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def describe_contour(contour: np.ndarray) -> None:\n",
    "    area = cv2.contourArea(contour) ###\n",
    "    print(f'Obsah kontury:             {area = }')\n",
    "\n",
    "    perimeter = cv2.arcLength(contour, True) ###\n",
    "    print(f'Obvod kontury:             {perimeter = }')\n",
    "\n",
    "    rect = cv2.minAreaRect(contour)\n",
    "    shape_width, shape_height = rect[1]\n",
    "\n",
    "    center = cv2.moments(contour) ###\n",
    "    center_x = int(center[\"m10\"] / center[\"m00\"])\n",
    "    center_y = int(center[\"m01\"] / center[\"m00\"])\n",
    "    print(f'Střed kontury:             {(center_x, center_y) = }')"
   ],
   "id": "e924ae3f6b4a3eb8",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:31:20.603867Z",
     "start_time": "2025-01-19T16:31:20.602107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def angle_lines(line1, line2):\n",
    "    x1, y1, x2, y2 = line1\n",
    "    x3, y3, x4, y4 = line2\n",
    "\n",
    "    angle1 = math.atan2(y1 - y2, x1 - x2)\n",
    "    angle2 = math.atan2(y3 - y4, x3 - x4)\n",
    "\n",
    "    return math.degrees(angle1 - angle2)"
   ],
   "id": "8070abab7bc789fa",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### HW01"
   ],
   "id": "dc3afbc03e514f09"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:31:20.620976Z",
     "start_time": "2025-01-19T16:31:20.610509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "import itertools\n",
    "from improutils import to_intensity, segmentation_two_thresholds, find_contours, load_image, crop, to_hsv, plot_images\n",
    "\n",
    "\n",
    "def hw01():\n",
    "    # načtení obrazu\n",
    "    img = load_image('images/basic.png')\n",
    "    img = crop(img, 440, 200, 1600, 900)\n",
    "    img_hsv = to_hsv(img)\n",
    "    plot_images(img,img_hsv)\n",
    "    # segmentace obdélníků\n",
    "    lower_bound = (to_intensity(18), 140, 149)\n",
    "    upper_bound = (to_intensity(64), 255, 201)\n",
    "\n",
    "    lower_bound_other = (to_intensity(314), 113, 0)\n",
    "    upper_bound_other = (to_intensity(360), 255, 255)\n",
    "\n",
    "    rect_others = segmentation_two_thresholds(img_hsv, lower_bound_other, upper_bound_other) ### prahy pro segmentaci v RGB\n",
    "    rect_ref = segmentation_two_thresholds(img_hsv, lower_bound, upper_bound) ### prahy pro segmentaci v RGB\n",
    "    rect_mask = cv2.add(rect_others, rect_ref)\n",
    "\n",
    "    # nalezení referenčního obdélníku podle velikosti kontury\n",
    "    drawn_ref, _, ref_cnt = find_contours(rect_mask, 30000, 85000)\n",
    "\n",
    "    # nalezení kontur všech obdélníků\n",
    "    drawn_ref_others, _, ref_cnt_others = find_contours(rect_mask, 10000)\n",
    "\n",
    "    ref_width_real = 40\n",
    "    ref_height_real = 80\n",
    "\n",
    "    # vypočtení poměru mm/pix\n",
    "    rect = cv2.minAreaRect(ref_cnt[0])\n",
    "    ref_width_image, ref_height_image = rect[1]\n",
    "    real_image_ratio = min(ref_width_real, ref_height_real) / min(ref_width_image, ref_height_image)\n",
    "\n",
    "    print(f'Recalculated size: {(ref_width_image*real_image_ratio, ref_height_image*real_image_ratio)}')\n",
    "    print(f'Ratio between real width and image width: {real_image_ratio}')\n",
    "\n",
    "\n",
    "    def get_bounding_rect_center(contour):\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        center_x = x + w // 2\n",
    "        center_y = y + h // 2\n",
    "        return (center_x, center_y)\n",
    "    contours = ref_cnt_others\n",
    "    contours = sorted(contours, key=lambda c: (get_bounding_rect_center(c)[0], get_bounding_rect_center(c)[1]))\n",
    "\n",
    "    contour_images = []\n",
    "\n",
    "    for contour in contours:\n",
    "        contour_images.append(img.copy())\n",
    "        cv2.drawContours(contour_images[-1], [contour], -1, color=(0, 255, 0 ), thickness=5)\n",
    "\n",
    "    plot_images(*contour_images,titles=[0,1,2,3,4],title_size=64)\n",
    "\n",
    "    index_list = list(range(len(contours)))\n",
    "    combinations = list(itertools.combinations(index_list , 2))\n",
    "\n",
    "    def line_segment_to_point_dist(l_pt1, l_pt2, dst_pt,ret_points=False):\n",
    "        x1, y1 = l_pt1\n",
    "        x2, y2 = l_pt2\n",
    "        x0, y0 = dst_pt\n",
    "\n",
    "        # Umocněná velikost úsečky\n",
    "        line_len_sq = (x2 - x1) ** 2 + (y2 - y1) ** 2\n",
    "\n",
    "        # Projekční faktor\n",
    "        t = ((x0 - x1) * (x2 - x1) + (y0 - y1) * (y2 - y1)) / line_len_sq\n",
    "\n",
    "        # Určíme vzdálenosti od bodu [x0,y0] vůči různým situacím\n",
    "        if t < 0:\n",
    "            # Vzdálenost od bodu [x1,y1]\n",
    "            proj_x = x1\n",
    "            proj_y = y1\n",
    "        elif t > 1:\n",
    "            # Vzdálenost od bodu [x2,y2]\n",
    "            proj_x = x2\n",
    "            proj_y = y2\n",
    "        else:\n",
    "            # Vzdálenost kolmice na úsečku\n",
    "            proj_x = x1 + t * (x2 - x1)\n",
    "            proj_y = y1 + t * (y2 - y1)\n",
    "\n",
    "        if ret_points:\n",
    "            return math.sqrt((x0 - proj_x) ** 2 + (y0 - proj_y) ** 2), [(x0,y0), [proj_x, proj_y]]\n",
    "        # Spočteme vzdálenost\n",
    "        return math.sqrt((x0 - proj_x) ** 2 + (y0 - proj_y) ** 2)\n",
    "\n",
    "    def line_segments_dist(l1_pt1, l1_pt2, l2_pt1, l2_pt2, ret_points = False):\n",
    "        # Vždy 2 možnosti bodu pro jednu úsečku\n",
    "        distances = [\n",
    "            line_segment_to_point_dist(l1_pt1, l1_pt2, l2_pt1,ret_points),\n",
    "            line_segment_to_point_dist(l1_pt1, l1_pt2, l2_pt2,ret_points),\n",
    "            line_segment_to_point_dist(l2_pt1, l2_pt2, l1_pt1,ret_points),\n",
    "            line_segment_to_point_dist(l2_pt1, l2_pt2, l1_pt2,ret_points)\n",
    "        ]\n",
    "\n",
    "        if not ret_points:\n",
    "            return min(distances)\n",
    "\n",
    "        min_distance, closest_points = min(distances, key=lambda x: x[0])\n",
    "\n",
    "        return min_distance, closest_points\n",
    "\n",
    "    def rect_dist(r1_pts, r2_pts, ret_points=False):\n",
    "        # Obdélník je tvořen 4 úsečkami\n",
    "        r1_segments = [\n",
    "            (r1_pts[0], r1_pts[1]),\n",
    "            (r1_pts[1], r1_pts[2]),\n",
    "            (r1_pts[2], r1_pts[3]),\n",
    "            (r1_pts[3], r1_pts[0])\n",
    "        ]\n",
    "\n",
    "        r2_segments = [\n",
    "            (r2_pts[0], r2_pts[1]),\n",
    "            (r2_pts[1], r2_pts[2]),\n",
    "            (r2_pts[2], r2_pts[3]),\n",
    "            (r2_pts[3], r2_pts[0])\n",
    "        ]\n",
    "        closest_pts = None\n",
    "\n",
    "        # Najdeme nejmenší vzdálenost mezi libovolnou úsečkou r1 a libovolnou úsečkou r2\n",
    "        min_distance = float('inf')\n",
    "        for seg1 in r1_segments:\n",
    "            for seg2 in r2_segments:\n",
    "                dist = line_segments_dist(seg1[0], seg1[1], seg2[0], seg2[1],ret_points)\n",
    "                if ret_points and dist[0] < min_distance:\n",
    "                    closest_pts = dist[1]\n",
    "                    min_distance = dist[0]\n",
    "                elif not ret_points and dist < min_distance:\n",
    "                    min_distance = dist\n",
    "\n",
    "        if ret_points:\n",
    "            return min_distance, closest_pts\n",
    "        else:\n",
    "            return min_distance\n",
    "\n",
    "    rectangles = [cv2.boxPoints(cv2.minAreaRect(cnt)) for cnt in contours]\n",
    "\n",
    "    for comb in combinations:\n",
    "        idx1, idx2 = comb\n",
    "\n",
    "        r1_pts = rectangles[idx1]\n",
    "        r2_pts = rectangles[idx2]\n",
    "\n",
    "        dist_px = rect_dist(r1_pts, r2_pts)\n",
    "\n",
    "        print(f\"{idx1} <-> {idx2}: {dist_px * real_image_ratio / 10:.2f} cm\")\n",
    "\n",
    "\n",
    "    image = img.copy()\n",
    "\n",
    "    for comb in combinations:\n",
    "        idx1, idx2 = comb\n",
    "        r1_pts = rectangles[idx1]\n",
    "        r2_pts = rectangles[idx2]\n",
    "\n",
    "        dist_px, (pt1, pt2) = rect_dist(r1_pts, r2_pts, True)\n",
    "\n",
    "        pt1, pt2 = map(tuple, map(lambda pt: map(int, pt), (pt1, pt2)))\n",
    "\n",
    "        dist_cm = dist_px * real_image_ratio / 10\n",
    "        cv2.line(image, pt1, pt2, color=(255, 0, 0), thickness=2)\n",
    "\n",
    "    # Rozdělené abych text vypsal přes čáry\n",
    "    for comb in combinations:\n",
    "        idx1, idx2 = comb\n",
    "        r1_pts = rectangles[idx1]\n",
    "        r2_pts = rectangles[idx2]\n",
    "\n",
    "        dist_px, (pt1, pt2) = rect_dist(r1_pts, r2_pts, True)\n",
    "\n",
    "        pt1, pt2 = map(tuple, map(lambda pt: map(int, pt), (pt1, pt2)))\n",
    "        position = tuple(map(int, ((pt1[0] + pt2[0]) / 2 - 30, (pt1[1] + pt2[1]) / 2 - 20)))\n",
    "\n",
    "        dist_cm = dist_px * real_image_ratio / 10\n",
    "        cv2.putText(image, f'{dist_cm:.2f}cm'.format(\".2f\"), position, cv2.FONT_HERSHEY_COMPLEX, 0.65, (255, 255, 255), 2, cv2.LINE_AA)"
   ],
   "id": "2234cef9ce25f5",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## library.ipynb"
   ],
   "id": "a8f408b16913ace7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:31:20.625914Z",
     "start_time": "2025-01-19T16:31:20.623825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def rotate_image(image, angle, image_center=None):\n",
    "    \"\"\" Rotates the input image by specified angle.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.ndarray\n",
    "        Image to be rotated.\n",
    "    angle : float\n",
    "        Rotation angle.\n",
    "    image_center : Optional[tuple(int, int)]\n",
    "        Center of rotation.\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Returns the rotated input image by specified angle.\n",
    "    \"\"\"\n",
    "    if image_center is None:\n",
    "        image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "    result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "    return result"
   ],
   "id": "c417a9c9d8f11b0b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:31:20.632482Z",
     "start_time": "2025-01-19T16:31:20.630085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from improutils import copy_to\n",
    "\n",
    "\n",
    "def draw_rotated_text(img, text, point, angle, text_scale, text_color, text_thickness):\n",
    "    img_filled = np.full(img.shape, text_color, dtype=np.uint8)\n",
    "    # create rotated text mask\n",
    "    text_mask = np.zeros((img.shape[0], img.shape[1]), dtype=np.uint8)\n",
    "    cv2.putText(text_mask, \"{:.2f} cm\".format(text), point, 0, text_scale, (255, 255, 255), text_thickness)\n",
    "    if angle > 0:\n",
    "        angle = -angle + 90\n",
    "    elif angle < 0:\n",
    "        angle = angle + 90\n",
    "    text_mask = rotate_image(text_mask, -angle, point)\n",
    "    result = copy_to(img_filled, img.copy(), text_mask)\n",
    "    return result"
   ],
   "id": "a1b42d82f2d1455d",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:31:20.644341Z",
     "start_time": "2025-01-19T16:31:20.639238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def create_slider(min, max, description):\n",
    "    description = description.ljust(30, '\\xa0')\n",
    "    return widgets.IntRangeSlider( min=min, max=max, step=1,value=[min,max],\n",
    "                                   description=description,\n",
    "                                   continuous_update=False,\n",
    "                                   orientation='horizontal',\n",
    "                                   style=dict(description_width='initial'),\n",
    "                                   layout=widgets.Layout(width='auto'),\n",
    "                                   )\n",
    "\n",
    "def multicolor_segmentation(func,colors):\n",
    "    \"\"\" Allows interactive HSV thresholding for multiple colors with saving and returning thresholds that are picked by the user.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    func : function\n",
    "        function with arguments hue = h_range (int, range: 0-360), saturation = s_range (int, range: 0-255), value = v_range (int, range: 0-255)\n",
    "    colors : list\n",
    "        list of colors that the user can choose from, e.g. ['red', 'green', 'blue'], these colors will be used as keys in the output dictionary\n",
    "    Returns\n",
    "    -------\n",
    "    color_thresholds: dict\n",
    "        Returns a dictionary with the chosen thresholds for each color, e.g. {'red': (0, 0, 0), 'green': (0, 0, 0), 'blue': (0, 0, 0)}, can be also empty if no thresholds were saved\n",
    "    \"\"\"\n",
    "    color_thresholds = {}\n",
    "\n",
    "    # initialize sliders, buttons etc.\n",
    "    h_slider=create_slider(min=0, max=360, description='Hue:')\n",
    "    s_slider=create_slider(min=0, max=255, description='Saturation:')\n",
    "    v_slider=create_slider(min=0, max=255, description='Value:')\n",
    "\n",
    "    color_dropdown = widgets.Dropdown(options=colors, description='Color:'.ljust(30, '\\xa0'), style ={'description_width': 'initial'},layout = {'width': 'max-content'})\n",
    "\n",
    "    save_button = widgets.Button(description='Save threshold for color',layout=widgets.Layout(width='auto'),button_style='success')\n",
    "    finish_button = widgets.Button(description='Return saved thresholds',layout=widgets.Layout(width='auto'),button_style='danger')\n",
    "\n",
    "    text_output = widgets.Output()\n",
    "    interactive_output = widgets.interactive_output(func,{'h_range':h_slider,'s_range':s_slider,'v_range':v_slider})\n",
    "\n",
    "    # widget layout\n",
    "    input_box = widgets.VBox([h_slider,s_slider,v_slider,color_dropdown])\n",
    "    button_box = widgets.HBox([save_button, finish_button])\n",
    "    other_box = widgets.VBox([text_output, interactive_output])\n",
    "\n",
    "    def reset_sliders():\n",
    "        h_slider.value = (0,360)\n",
    "        s_slider.value = (0,255)\n",
    "        v_slider.value = (0,255)\n",
    "\n",
    "    # button callbacks\n",
    "    def on_save_clicked(b):\n",
    "        with text_output:\n",
    "            text_output.clear_output()\n",
    "            color_thresholds[color_dropdown.value] = (h_slider.value, s_slider.value, v_slider.value)\n",
    "            print(f\"Saved for color '{color_dropdown.value}', threshold: {color_thresholds[color_dropdown.value]}\\nResetting sliders...\\nChanging to next color...\")\n",
    "            reset_sliders()\n",
    "            # set next color in dropdown\n",
    "            color_dropdown.value = colors[(colors.index(color_dropdown.value)+1)%len(colors)]\n",
    "\n",
    "\n",
    "    def on_finish_clicked(b):\n",
    "        with text_output:\n",
    "            text_output.clear_output()\n",
    "            print('Returned saved thresholds!')\n",
    "            reset_sliders()\n",
    "\n",
    "\n",
    "    save_button.on_click(on_save_clicked)\n",
    "    finish_button.on_click(on_finish_clicked)\n",
    "    # display widget\n",
    "    display(input_box, button_box,other_box)\n",
    "\n",
    "    return color_thresholds"
   ],
   "id": "712674f4cb879e3d",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Extra"
   ],
   "id": "e7dc180dcdcd1703"
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "# pomocné funkce z vedlejšího notebooku se nechtěly kamarádit (neměly k dispozici cv2 modul, nechápu proč)\n",
    "\n",
    "def tuple_elems_to_int(t):\n",
    "    '''Converts all values of input tuple to ints.'''\n",
    "    assert len(t) == 2, 'Only tuple with two elements is supported!'\n",
    "    return (int(t[0]), int(t[1]))\n",
    "\n",
    "def kq_of_line_segment(l_p1, l_p2):\n",
    "    '''Computes slope (k) and translation (q) of input line segment defined with two points.'''\n",
    "    a = np.array([[l_p1[0], 1], [l_p2[0], 1]])\n",
    "    b = np.array([l_p1[1], l_p2[1]])\n",
    "\n",
    "    k, q = np.linalg.solve(a, b)\n",
    "\n",
    "    return k, q\n",
    "\n",
    "def normal_kq_in_point(p1, k, q):\n",
    "    '''Computes slope (kn) and translation (qn) of normal (perpendicular) line in point p1.'''\n",
    "    kn = -1/k\n",
    "    qn = p1[1] - kn * p1[0]\n",
    "    return kn, qn\n",
    "\n",
    "def normal_line_start_end_points(point, k, q, dx):\n",
    "    '''Computes pixel points of perpendicular line segment of lenght dx in point point\n",
    "    to line defined by k and q.'''\n",
    "    kn, qn = normal_kq_in_point(point, k, q)\n",
    "\n",
    "    x = [point[0]-dx, point[0]+dx]\n",
    "    y = [kn * x[0] + qn, kn * x[1] + qn]\n",
    "\n",
    "    return (x[0], y[0]), (x[1], y[1])\n",
    "\n",
    "def draw_norm_line_segment_in_point(l_p1, l_p2, point, dx, image):\n",
    "    '''Draws perpendicular line segments to line defined with two points of lenght dx\n",
    "    in point point to input image.'''\n",
    "    k,q = kq_of_line_segment(l_p1, l_p2)\n",
    "    start, end = normal_line_start_end_points(point, k, q, dx)\n",
    "    cv2.line(image, tuple_elems_to_int(start), tuple_elems_to_int(end), (255,255,255), 1, cv2.LINE_4)\n",
    "    return image\n",
    "\n",
    "def draw_contour(image, contour):\n",
    "    '''Draws input contour into image with white color.'''\n",
    "    cv2.drawContours(image, contour, -1, (255,255,255), 1, cv2.LINE_4)\n",
    "    return image"
   ],
   "id": "2e18d859c131e248"
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)  ###\n",
    "vps = compute_vanishing_points(img_rgb)\n",
    "vp1 = vps[0]\n",
    "vp2 = vps[2]\n",
    "vpz = vps[1]  # vertikální úběžník, v ose pozadí/sledovaných objektů\n",
    "\n",
    "vl = np.cross(vp1, vp2)\n",
    "REFERENCE_MEASUREMENTS = [\n",
    "    # (bod_na_zemi, bod_ve_vysce, vyska)\n",
    "    ((515, 601), (519, 795), 26.),  ###\n",
    "    ((723, 607), (726, 802), 26.),  ###\n",
    "    ((717, 391), (726, 799), 56.),  ###\n",
    "    ((936, 392), (938, 809), 56.),  ###\n",
    "]\n",
    "\n",
    "# Vytvoření objektu pro výpočet odhadu výšky objektu a zavolání funkce\n",
    "height_estimator = HeightEstimator(REFERENCE_MEASUREMENTS, vl, vpz)\n",
    "height = abs(height_estimator.calc_height(Tx, Bx))\n",
    "\n",
    "# Výstup\n",
    "print(f'Objekt {height:.2f} mm')\n",
    "## Hloubkové kamery (07)\n"
   ],
   "id": "b0d1f557ecc1a9c0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## library.py"
   ],
   "id": "eda3ae26a2cf2e89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T12:39:37.278580Z",
     "start_time": "2025-01-20T12:39:34.082923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Dict, Union\n",
    "from pathlib import Path\n",
    "from prettytable import PrettyTable\n",
    "from improutils import *\n",
    "\n",
    "def camera_calibration(calib_path: str,\n",
    "                       chess_shape: Tuple[int,int],\n",
    "                       cv2_flags:int = 0,\n",
    "                       extensions: List[str] = [\"jpg\", \"jpeg\" ,\"png\", \"tiff\", \"bmp\"]) -> Tuple[float,\n",
    "np.ndarray,\n",
    "np.ndarray,\n",
    "Tuple[np.ndarray],\n",
    "Tuple[np.ndarray],\n",
    "np.ndarray,\n",
    "np.ndarray,\n",
    "np.ndarray,\n",
    "Dict[str,np.ndarray]]:\n",
    "    \"\"\"Calibrates camera from images with chessboard pattern, using OpenCV's cv2.calibrateCameraExtended function\n",
    "\n",
    "    Args:\n",
    "        calib_path (str): path to the folder containing chessboard pattern images\n",
    "        chess_shape (Tuple[int,int]): interior corner count in the format of rows, columns\n",
    "        cv2_flags (int, optional): additional OpenCV's flags for cv2.calibrateCameraExtended. Defaults to 0.\n",
    "        extensions (List[str], optional): allowed image extensions. Defaults to [\"jpg\", \"jpeg\" ,\"png\", \"tiff\"].\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if calibration images have different sizes\n",
    "        ValueError: if no calibration images were found or could not be read from the provided path\n",
    "        ValueError: if no chessboard patterns were detected in the images\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, np.ndarray, np.ndarray, Tuple[np.ndarray], Tuple[np.ndarray], np.ndarray, np.ndarray, np.ndarray, Dict[str,np.ndarray]]:\n",
    "        returns the output from cv2.calibrateCameraExtended and dictionary with image names as keys and images with drawn chessboard corners as values\n",
    "    \"\"\"\n",
    "    print(f\"Processing images from {calib_path} with possible extensions {extensions}\")\n",
    "    def correct_extension(path, extensions):\n",
    "        return path.is_file() and path.suffix[1:].lower() in extensions\n",
    "    # termination criteria for subpixel corner detection\n",
    "    # by default it is set to 30 iterations and epsilon = 0.001\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((chess_shape[0] * chess_shape[1], 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:chess_shape[0], 0:chess_shape[1]].T.reshape(-1, 2)\n",
    "\n",
    "    # arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3D point in real world space\n",
    "    imgpoints = [] # 2D points in image plane.\n",
    "\n",
    "    image_paths = sorted([path for path in Path(calib_path).glob(\"*\") if correct_extension(path,extensions)])\n",
    "    chess_brd_images = 0\n",
    "    read_images = 0\n",
    "    chessboard_images = {}\n",
    "    img_size = None\n",
    "    for img_path in image_paths:\n",
    "        img_name = img_path.name\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"File {img_name} could not be read, skipping...\")\n",
    "            continue\n",
    "        else:\n",
    "            read_images += 1\n",
    "            if img_size is None:\n",
    "                # need to be in the format of width, height\n",
    "                img_size = img.shape[:2][::-1]\n",
    "            else:\n",
    "                if img_size != img.shape[:2][::-1]:\n",
    "                    raise ValueError(\"All images must have same size.\")\n",
    "            print(f\"File {img_name} is being processed...\")\n",
    "\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # find the chess board corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, chess_shape, None)\n",
    "\n",
    "        # if found, add object points, image points (after refining them)\n",
    "        if ret:\n",
    "            chess_brd_images += 1\n",
    "            print(f\"\\t Corners found!\")\n",
    "            objpoints.append(objp)\n",
    "            subpix_corners = cv2.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
    "            imgpoints.append(subpix_corners)\n",
    "\n",
    "            chessboard_images[img_name] = cv2.drawChessboardCorners(img, chess_shape, subpix_corners, ret)\n",
    "\n",
    "        else:\n",
    "            print(f\"\\t Corners NOT found!\")\n",
    "            continue\n",
    "\n",
    "    print(f\"Number of images with detected chessboard: {chess_brd_images}/{read_images}\")\n",
    "\n",
    "    if read_images == 0:\n",
    "        raise ValueError(\"No images were read from the provided path.\")\n",
    "\n",
    "    if chess_brd_images == 0:\n",
    "        raise ValueError(\"No chessboard patterns were detected in the images.\")\n",
    "\n",
    "    calib_values = cv2.calibrateCameraExtended(objpoints, imgpoints, img_size, cameraMatrix=None, distCoeffs=None, flags=cv2_flags, criteria=criteria)\n",
    "    reprojection_error, camera_matrix, dist_coeffs, rvecs, tvecs, std_deviations_intrinsics, std_deviations_extrinsics, per_view_errors = calib_values\n",
    "    return reprojection_error, camera_matrix, dist_coeffs, rvecs, tvecs, std_deviations_intrinsics, std_deviations_extrinsics, per_view_errors, chessboard_images\n",
    "\n",
    "def calibration_stats(reprojection_error:float,\n",
    "                      camera_matrix: np.ndarray,\n",
    "                      dist_coeffs:np.ndarray,\n",
    "                      std_deviations_intrinsics:np.ndarray=None,\n",
    "                      per_view_errors:np.ndarray=None,\n",
    "                      view_names:List[str]=None,\n",
    "                      pixel_size:Union[float,Tuple[float,float]]=None) -> None:\n",
    "    \"\"\"Prints calibration statistics using.\n",
    "    RMS re-projection error, estimated intrinsics and distortion parameters, standard deviations of intrinsics, focal length in millimeters and per view reprojection errors.\n",
    "\n",
    "    Args:\n",
    "        reprojection_error (float): re-projection error from cv2.calibrateCamera\n",
    "        camera_matrix (np.ndarray): camera matrix from cv2.calibrate\n",
    "        dist_coeffs (np.ndarray): distortion coefficients from cv2.calibrateCamera\n",
    "        std_deviations_intrinsics (np.ndarray, optional): std_deviations_intrinsics from cv2.calibrateCameraExtended. Defaults to None.\n",
    "        per_view_errors (np.ndarray, optional): per_view_errors from cv2.calibrateCameraExtended. Defaults to None.\n",
    "        view_names (List[str], optional): image names for which we detected the chessboard. Defaults to None.\n",
    "        pixel_size (Union[float,Tuple[float,float]], optional): size of physical pixels of a camera in micrometers eg. 4.8 or 5.86 or [5.86, 4.8] for non square pixels. Defaults to None.\n",
    "    \"\"\"\n",
    "    # opencv always returns atleast 4 distortion coefficients\n",
    "    params_amount = 4 + dist_coeffs.shape[1]\n",
    "\n",
    "    parameters = [\"fx\", \"fy\", \"cx\", \"cy\", \"k1\", \"k2\", \"p1\", \"p2\", \"k3\", \"k4\", \"k5\", \"k6\", \"s1\", \"s2\", \"s3\", \"s4\", \"Tx\", \"Ty\"]\n",
    "    units = [\"pixels\"] * 4 + [\"unitless\"] * (params_amount - 4)\n",
    "\n",
    "    print(f\"RMS re-projection error: {reprojection_error:.5f} pixels\")\n",
    "\n",
    "    print(f\"\\nEstimated intrinsics parameters\")\n",
    "    intrinsics_table = PrettyTable()\n",
    "    intrinsics_table.add_column(\"Parameter\", parameters[:4])\n",
    "    intrinsics_table.add_column(\"Estimated Value\", [f\"{val:.5f}\" for val in [camera_matrix[0, 0], camera_matrix[1, 1], camera_matrix[0, 2], camera_matrix[1, 2]]])\n",
    "    intrinsics_table.add_column(\"Unit\", units[:4])\n",
    "    print(intrinsics_table)\n",
    "\n",
    "    print(f\"\\nEstimated Distortion parameters\")\n",
    "    distortion_table = PrettyTable()\n",
    "    distortion_table.add_column(\"Parameter\", parameters[4:params_amount])\n",
    "    distortion_table.add_column(\"Distortion\", [f\"{val:.5f}\" for val in dist_coeffs[0, :params_amount-4]])\n",
    "    distortion_table.add_column(\"Unit\", units[4:params_amount])\n",
    "    print(distortion_table)\n",
    "\n",
    "    if std_deviations_intrinsics is not None:\n",
    "        print(f\"\\nIntrinsic parameters standard deviation\")\n",
    "        intrinsics_std_table = PrettyTable()\n",
    "        intrinsics_std_table.add_column(\"Parameter\", parameters[:params_amount])\n",
    "        intrinsics_std_table.add_column(\"Value\", [f\"±{val:.5f}\" for val in std_deviations_intrinsics[:params_amount,0]])\n",
    "        intrinsics_std_table.add_column(\"Unit\", units[:params_amount])\n",
    "        print(intrinsics_std_table)\n",
    "\n",
    "    if pixel_size is not None and std_deviations_intrinsics is not None:\n",
    "        if not isinstance(pixel_size, tuple):\n",
    "            pixel_size = (pixel_size, pixel_size)\n",
    "        print(f\"\\nEstimated Focal length in millimeters\")\n",
    "        focal_length_table = PrettyTable()\n",
    "        focal_length_table.add_column(\"Parameter\", parameters[:2])\n",
    "        focal_length_table.add_column(\"Value ± Std Deviation\", [f\"{val*pix_size/1000:.5f} ± {std*pix_size/1000:.5f}\" for val, pix_size, std in zip([camera_matrix[0, 0], camera_matrix[1, 1]], pixel_size, std_deviations_intrinsics[:2,0])])\n",
    "        focal_length_table.add_column(\"Unit\", [\"millimeter\"] * 2)\n",
    "        print(focal_length_table)\n",
    "\n",
    "    if per_view_errors is not None:\n",
    "        print(f\"\\nPer view reprojection errors\")\n",
    "        view_error_table = PrettyTable()\n",
    "        # Sort the view names and errors by the errors in descending order\n",
    "        sorted_views_and_errors = sorted(zip(view_names, per_view_errors[:,0]), key=lambda x: x[1], reverse=True)\n",
    "        sorted_view_names, sorted_errors = zip(*sorted_views_and_errors)\n",
    "        view_error_table.add_column(\"Image name\", sorted_view_names)\n",
    "        view_error_table.add_column(\"Re-projection error (sorted)\", [f\"{val:.5f}\" for val in sorted_errors])\n",
    "        view_error_table.add_column(\"Unit\", [\"pixels\"] * len(sorted_view_names))\n",
    "        print(view_error_table)\n",
    "\n",
    "def correct_frame(img, camera_matrix, dist_coeffs):\n",
    "    \"\"\"Returns undistorted image.\"\"\"\n",
    "    return cv2.undistort(img, camera_matrix, dist_coeffs)\n",
    "\n",
    "def _plot_grid(xv, yv, squares, ax):\n",
    "    for i  in np.linspace(0, xv.shape[1] - 1, squares+1, dtype=int):\n",
    "        ax.plot(xv[i,:], yv[i,:], 'k-')\n",
    "    for j in np.linspace(0, xv.shape[0] - 1, squares+1, dtype=int):\n",
    "        ax.plot(xv[:,j], yv[:,j], 'k-')\n",
    "\n",
    "    ax.axis('off')\n",
    "\n",
    "def _radial_distortion(xv, yv, k):\n",
    "    xv_radial = np.zeros_like(xv)\n",
    "    yv_radial = np.zeros_like(yv)\n",
    "    for i in range(xv.shape[0]):\n",
    "        for j in range(xv.shape[1]):\n",
    "            r = np.sqrt(xv[i,j]**2 + yv[i,j]**2)\n",
    "            radial = (1 + (k[0]*(r**2) + k[1]*(r**4) + k[2]*(r**6)))/(1 + (k[3]*(r**2) + k[4]*(r**4) + k[5]*(r**6)))\n",
    "            xv_radial[i,j] = xv[i,j]*radial\n",
    "            yv_radial[i,j] = yv[i,j]*radial\n",
    "    return xv_radial, yv_radial\n",
    "\n",
    "def _tangetial_distortion(xv, yv, p):\n",
    "    xv_tang = np.zeros_like(xv)\n",
    "    yv_tang = np.zeros_like(yv)\n",
    "    for i in range(xv.shape[0]):\n",
    "        for j in range(xv.shape[1]):\n",
    "            x = xv[i,j]\n",
    "            y = yv[i,j]\n",
    "            r = np.sqrt(x**2 + y**2)\n",
    "            x_tang = x + (2*p[0]*x*y + p[1]*(r**2 + 2*x**2))\n",
    "            y_tang = y + (p[0]*(r**2 + 2*y**2) + 2*p[1]*x*y)\n",
    "            xv_tang[i,j] = x_tang\n",
    "            yv_tang[i,j] = y_tang\n",
    "    return xv_tang, yv_tang\n",
    "\n",
    "def plot_distortion(k1:float,k2:float,k3:float,k4:float,k5:float,k6:float, p1:float,p2:float) -> None:\n",
    "    \"\"\"Plots radial, tangential and compounded (radial + tangential) distortion grid. Using the Brown-Conrady model.\n",
    "\n",
    "    Args:\n",
    "        k1 (float): radial distortion coefficient\n",
    "        k2 (float): radial distortion coefficient\n",
    "        k3 (float): radial distortion coefficient\n",
    "        k4 (float): radial distortion coefficient\n",
    "        k5 (float): radial distortion coefficient\n",
    "        k6 (float): radial distortion coefficient\n",
    "        p1 (float): tangential distortion coefficient\n",
    "        p2 (float): tangential distortion coefficient\n",
    "    \"\"\"\n",
    "    k = (k1,k2,k3,k4,k5,k6)\n",
    "    p = (p1,p2)\n",
    "    squares = 10 # amount of squares in the grid\n",
    "    pts = 100\n",
    "    # realistical values for image with 2500 x 2500 pixels with focal length of 35mm which is close to 10500 pixels with basler camera pixel size, origin is in the center - therfore x and y should be within values +-(2500/10500)/2\n",
    "    width = 0.23\n",
    "    height = 0.23\n",
    "    xv, yv = np.meshgrid(np.linspace(-width/2,width/2,pts), np.linspace(-height/2,height/2,pts))\n",
    "\n",
    "    xv_radial, yv_radial = _radial_distortion(xv, yv, k)\n",
    "    xv_tang, yv_tang = _tangetial_distortion(xv, yv, p)\n",
    "\n",
    "    _, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    _plot_grid(xv_radial, yv_radial, squares, axs[0])\n",
    "    axs[0].set_title('Radial distortion grid')\n",
    "\n",
    "    _plot_grid(xv_tang, yv_tang, squares, axs[1])\n",
    "    axs[1].set_title('Tangential distortion grid')\n",
    "\n",
    "    _plot_grid(xv_radial + xv_tang, yv_radial + yv_tang, squares, axs[2])\n",
    "    axs[2].set_title('Compounded distortion grid')\n",
    "    plt.show()\n"
   ],
   "id": "49f86ee587729df",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Segmentace a vykresleni"
   ],
   "id": "d627fec3d7187a54"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def seg_and_draw():\n",
    "    image_path = 'img.jpg'\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(\"Image not found. Check the file path!\")\n",
    "\n",
    "    # Convert the image to grayscale for thresholding\n",
    "    grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Define thresholds for two segmentations\n",
    "    threshold1 = 100\n",
    "    threshold2 = 200\n",
    "\n",
    "    # Apply segmentation\n",
    "    segmented_mask1 = segmentation_one_threshold(grayscale_image, threshold1)\n",
    "    segmented_mask2 = segmentation_one_threshold(grayscale_image, threshold2)\n",
    "\n",
    "    # Create a red mask for the first segmentation\n",
    "    red_mask = np.zeros_like(image)\n",
    "    red_mask[:, :, 2] = 255  # Red channel\n",
    "\n",
    "    # Apply the red mask to the original image\n",
    "    red_overlay = cv2.addWeighted(image, 0.7, red_mask, 0.3, 0) # 0.7 img, 0.3 mask\n",
    "    segmented_image1 = np.where(segmented_mask1[:, :, None] == 255, red_overlay, image)\n",
    "\n",
    "    # Apply the second segmentation to display only the original colors\n",
    "    segmented_image2 = cv2.bitwise_and(image, image, mask=segmented_mask2)\n",
    "\n",
    "    plot_images(image, segmented_image1, segmented_image2)"
   ],
   "id": "3dc1682a0dc701a0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## HW4"
   ],
   "id": "ca49d88772e87b39"
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "def segment_components(mask,threshold=43.0, aspect_ratio_tolerance=0.2):\n",
    "    mask = np.zeros_like(mask, dtype=np.uint8)\n",
    "    mask[warped_thermal > threshold] = 255\n",
    "\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    filtered_contours = []\n",
    "    for contour in contours:\n",
    "        # obdélník ohraničující konturu\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        aspect_ratio = w / h if h > 0 else 0\n",
    "\n",
    "        # kontrola zda je kontura cca čtverec\n",
    "        if 1 - aspect_ratio_tolerance <= aspect_ratio <= 1 + aspect_ratio_tolerance:\n",
    "            filtered_contours.append(contour)\n",
    "\n",
    "    return filtered_contours, mask\n",
    "\n",
    "T_min = 43.0\n",
    "T_max = 50.0\n",
    "\n",
    "mask = np.zeros_like(mask, dtype=np.uint8)\n",
    "mask[(warped_thermal >= T_min) & (warped_thermal <= T_max)] = 255\n",
    "\n",
    "cnts, mask2 = segment_components(mask)\n",
    "\n",
    "segmented_mask = np.zeros_like(mask2)\n",
    "cv2.drawContours(segmented_mask, cnts, -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "plot_images(segmented_mask,titles=[f'Binární maska ({T_min}°C - {T_max}°C)'])"
   ],
   "id": "efe66f11d9eb345c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T10:05:44.080916Z",
     "start_time": "2025-01-21T10:05:44.078425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import improutils\n",
    "#help(improutils.find_contours)"
   ],
   "id": "961af4075a62ad6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function find_contours in module improutils.preprocessing.contours:\n",
      "\n",
      "find_contours(img_bin, min_area=0, max_area=inf, fill=True, external=True)\n",
      "    Finds contours in binary image and filters them using their area. Then it draws binary image\n",
      "    from filtered contours. It counts contours as well.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    img_bin : ndarray\n",
      "        Input binary image.\n",
      "    min_area : int\n",
      "        Size of contour that is used to filter all smaller contours out.\n",
      "    max_area : int\n",
      "        Size of contour that is used to filter all larger contours out.\n",
      "    Returns\n",
      "    -------\n",
      "    contour_drawn : ndarray\n",
      "        Output binary image with drawn filled filtered contours.\n",
      "    count : int\n",
      "        Number of found and filtered contours.\n",
      "    contours : list\n",
      "        Found contours.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5d5da205625adbd7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
