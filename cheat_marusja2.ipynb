{
    "cells": [
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": [
                "## SVZ cheatsheet\n",
                "### marusja2 - 2024/2025"
            ],
            "id": "8a77807f92f26ee"
        },
        {
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2025-01-19T16:31:18.570777Z",
                    "start_time": "2025-01-19T16:31:18.455601Z"
                }
            },
            "cell_type": "code",
            "source": [
                "import cv2\n",
                "import numpy as np"
            ],
            "id": "2cd5fac4797c2615",
            "outputs": [],
            "execution_count": 1
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": [
                "# Dokumentace\n",
                "\n",
                "- help(funkce) - zobraz\u00ed n\u00e1pov\u011bdu k funkci\n",
                "- [Improutils - FIT Gitlab](https://gitlab.fit.cvut.cz/bi-svz/improutils_package)\n",
                "- [Improutils - Github](https://github.com/ImprolabFIT/improutils)\n",
                "- [Improutils - Docs](https://improutils.readthedocs.io/en/master/)\n",
                "- [OpenCV](https://docs.opencv.org/4.x/)"
            ],
            "id": "7b378ec13eafff9d"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": [
                "# V\u00fdb\u011br sn\u00edmac\u00ed soustavy"
            ],
            "id": "c7e45d7dade697ac"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": [
                "## V\u00fdb\u011br kamery\n",
                "\n",
                "| Parametr                    | jednotka | ozna\u010den\u00ed |\n",
                "|-----------------------------|----------|----------|\n",
                "| Rozli\u0161en\u00ed kamery v pixelech | px       | $r$      |\n",
                "| Maxim\u00e1ln\u00ed velikost objektu  | mm       | $w$      |\n",
                "| P\u0159esnost (nejmen\u0161\u00ed rozd\u00edl)  | mm       | $p$      |\n",
                "\n",
                "Pot\u0159eba zvolit takovou kameru, \u017ee plat\u00ed:\n",
                "\n",
                "$$r \\geq \\frac{1.1 \\cdot w}{p / 2} = 2.2 \\frac{w}{p}$$\n",
                "\n",
                "- Hodnota $1.1$ v \u010ditateli jako p\u0159esah zorn\u00e9ho pole (5 % na ka\u017ed\u00e9 stran\u011b)\n",
                "- Hodnota $2$ ve jmenovateli... alespo\u0148 dva pixely pro zm\u011bnu kontrastu (jeden b\u00edl\u00fd, jeden \u010dern\u00fd)\n",
                "\n",
                "## P\u0159\u00edklad\n",
                "\n",
                "M\u011b\u0159en\u00ed objekt\u016f 20 mm a men\u0161\u00edch, pot\u0159eba p\u0159esnost 0.01 mm.\n",
                "\n",
                "$$\n",
                "\\begin{aligned}\n",
                "w = 20 \\text{\\ mm}, p = 0.01 \\text{\\ mm} \\ \\\n",
                "    r_{min} = 2.2 \\cdot \\frac{20}{0.01} = 2.2 \\cdot 2000 = 4400 \\text{\\ px}\n",
                "\\end{aligned}\n",
                "$$"
            ],
            "id": "715cc1cc8895ac9"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": [
                "## V\u00fdb\u011br objektivu\n",
                "\n",
                "Na z\u00e1klad\u011b parametr\u016f \u00falohy $Y, L$ a vybran\u00e9 kamery $Y'$:\n",
                "\n",
                "| Parametr                                      | jednotka | ozna\u010den\u00ed |\n",
                "|-----------------------------------------------|----------|----------|\n",
                "| Maxim\u00e1ln\u00ed velikost objektu                    | mm       | $Y$      |\n",
                "| Velikost obrazu (del\u0161\u00ed ze dvou stran)         | mm       | $Y'$     |\n",
                "| Pracovn\u00ed vzd\u00e1lenost (objekt-povrch objektivu) | mm       | $L$      |\n",
                "| Ohniskov\u00e1 vzd\u00e1lenost objektivu                | mm       | $f$      |\n",
                "\n",
                "Pot\u0159eba zvolit takov\u00fd objektiv, \u017ee plat\u00ed:\n",
                "\n",
                "$$f = Y' \\cdot \\frac{L}{1.1 \\cdot Y}$$\n",
                "\n",
                "Pokud m\u00e1me mo\u017enou vzd\u00e1lenost v rozsahu $[L_\\min, L_\\max]$, potom:\n",
                "\n",
                "$$Y' \\cdot \\frac{L_\\min}{1.1 \\cdot Y} \\leq f \\leq Y' \\cdot \\frac{L_\\max}{1.1 \\cdot Y}$$\n",
                "\n",
                "Hodnota $1.1$ ve jmenovateli jako p\u0159esah zorn\u00e9ho pole (5 % na ka\u017ed\u00e9 stran\u011b)\n",
                "\n",
                "## P\u0159\u00edklad\n",
                "\n",
                "M\u011b\u0159en\u00ed objekt\u016f 200 mm a men\u0161\u00edch, kamera mus\u00ed b\u00fdt um\u00edst\u011bna ve vzd\u00e1lenosti $[400, 600] \\text{\\ mm}$. Zvolen\u00e1 kamera m\u00e1 sn\u00edmac\u00ed \u010dip o velisosti $7.2 \\times 5.4 \\text{\\ mm}$.\n",
                "\n",
                "$$\n",
                "\\begin{aligned}\n",
                "Y = 200 \\text{\\ mm}, Y' = 7.2 \\text{\\ mm}, L \\in [400, 600] \\text{\\ mm} \\\\\n",
                "f_\\min = Y' \\cdot \\frac{L_\\min}{1.1 \\cdot Y} = 7.2 \\cdot \\frac{400}{1.1 \\cdot 200} = 13.09 \\text{\\ mm} \\\\\n",
                "f_\\max = Y' \\cdot \\frac{L_\\max}{1.1 \\cdot Y} = 7.2 \\cdot \\frac{600}{1.1 \\cdot 200} = 19.64 \\text{\\ mm} \\\\\n",
                "\\end{aligned}\n",
                "$$\n",
                "\n",
                "M\u016f\u017eeme tedy zvolit nap\u0159. objektiv s $f=16 \\text{\\ mm}$.\n",
                "\n",
                "V takov\u00e9m p\u0159\u00edpad\u011b zvol\u00edme pracovn\u00ed vzd\u00e1lenost $L = f \\cdot \\frac{1.1 \\cdot Y}{Y'} = 488.8 \\text{\\ mm}$. Kamera ale bude um\u00edst\u011bna d\u00e1l, a to o d\u00e9lku objektivu!!! Treba jeste pricteme 28mm (dle specsheetu delky objektivu napr).\n",
                "\n",
                "Pokud i tak nerozhodnome objektiv, tak lze vybrat dle velikosti snimace. (objektiv by mel byt blizko a spis vetsi) 1/1.8\" apod."
            ],
            "id": "bb5696e9f9dc702"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": [
                "# Nastaven\u00ed sn\u00edmac\u00ed soustavy\n",
                "- kamera - rozli\u0161en\u00ed, barevn\u00fd rozsah (RGB,mono), velikost senzoru\n",
                "- objektiv - ohniskov\u00e1 vzd\u00e1lenost, rozsah clony, velikost objektivu (v\u011bt\u0161\u00ed nebo rovna velikosti senzoru), rozsah ost\u0159en\u00ed\n",
                "- sv\u011btla"
            ],
            "id": "2f0569a152af97b"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": [
                "Pracovn\u00ed vzd\u00e1lenost (okraj objektivu - povrch objektu)\n",
                "- vs. minim\u00e1ln\u00ed pracovn\u00ed vzd\u00e1lenost objektivu\n",
                "\n",
                "Kamera\n",
                "- rozli\u0161en\u00ed obr\u00e1zku (p\u0159ed o\u0159ezem)\n",
                "- -> pom\u011br stran\n",
                "- barevn\u00fd rozsah (\u010dernob\u00edl\u00e1/RGB, po\u010det bit\u016f na barvu)\n",
                "- video... framerate (sn\u00edmkovac\u00ed frekvence)\n",
                "- fyzick\u00e1 velikost senzoru (nap\u0159. `1/1.8\"`, 1\" = 16 mm, m\u011b\u0159eno na diagon\u00e1le)\n",
                "- -> velikost pixelu, mm/px; **p\u0159esnost** = dvojn\u00e1sobek velikosti pixelu\n",
                "\n",
                "Objektiv\n",
                "- ohniskov\u00e1 vzd\u00e1lenost (nap\u0159. `f = 8 mm`, v pr\u016fmyslu v\u011bt\u0161inou pevn\u00e1)\n",
                "- rozsah clony (nap\u0159. `F 1.4 - 16.0`), pod\u00edl ohniskov\u00e9 vzd\u00e1lenosti a pr\u016fm\u011bru otvoru clony\n",
                "- fyzick\u00e1 velikost objektivu (nap\u0159. `1/1.8\"` nebo `7,2 x 5,4 mm`), **v\u011bt\u0161\u00ed nebo rovna velikosti senzoru**\n",
                "\n",
                "Nasv\u00edcen\u00ed\n",
                "- Sm\u011brov\u00e9... soust\u0159ed\u00ed se p\u0159\u00edmo na objekt, rovnob\u011b\u017en\u00e9 paprsky\n",
                "    - nereflexivn\u00ed povrchy\n",
                "    - **zv\u00fdrazn\u011bn\u00ed reli\u00e9fu**\n",
                "- Dif\u00fazn\u00ed/rozpt\u00fdlen\u00e9 sv\u011btlo... nep\u0159\u00edm\u00e9\n",
                "    - leskl\u00e9 povrchy\n",
                "    - \u010dasto jako diuzor p\u0159es klasick\u00e9 (p\u0159\u00edm\u00e9) sv\u011btlo\n",
                "    - **skryt\u00ed reli\u00e9fu**\n",
                "- Zadn\u00ed... pou\u017eit\u00ed pro maxim\u00e1ln\u00ed **zv\u00fdrazn\u011bn\u00ed obrysu**\n",
                "    - se siln\u00fdm difuzorem\n",
                "    - Nej\u010dast\u011bji se pou\u017e\u00edv\u00e1 ke zji\u0161\u0165ov\u00e1n\u00ed p\u0159\u00edtomnosti/nep\u0159\u00edtomnosti otvor\u016f/mezer, ke zji\u0161t\u011bn\u00ed orientace objekt\u016f, \u010di k jejich m\u011b\u0159en\u00ed\n",
                "- Dark Field... velk\u00e9 mno\u017estv\u00ed LED diod okolo objektu, sv\u00edt\u00ed pod ostr\u00fdm bo\u010dn\u00edm \u00fahlem\n",
                "    - **velk\u00e9 zv\u00fdrazn\u011bn\u00ed reli\u00e9fu**, vyryt\u00fdch/vytla\u010den\u00fdch n\u00e1pis\u016f atd.\n",
                "- Kopulov\u00e9... Opak dark fieldu, sv\u011btlo p\u0159ich\u00e1z\u00ed ze v\u0161ech stran, rovnom\u011brn\u011b\n",
                "    - **maxim\u00e1ln\u00ed skryt\u00ed reli\u00e9fu**\n",
                "- *Koaxi\u00e1ln\u00ed*... d\u00edky propustn\u00e9mu zrcadlu sv\u011btlo ze stejn\u00e9ho sm\u011bru, jako kamera\n",
                "    - DOAL = Diffused On Axis Light\n",
                "    - elimance odlesk\u016f, zv\u00fdrazn\u011bn\u00ed detail\u016f"
            ],
            "id": "257b1ca03fd87824"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": [
                "### Vin\u011btace\n",
                "tmav\u00e9 rohy obr\u00e1zku, do roh\u016f senzoru nedopad\u00e1 dostatek sv\u011btla (oproti st\u0159edu)\n",
                "\n",
                "P\u0159\u00ed\u010diny:\n",
                "- konstrukce objektivu (p\u0159\u00edli\u0161 \u00fazk\u00fd)\n",
                "- p\u0159\u00edli\u0161 **otev\u0159en\u00e1** clona\n",
                "\n",
                "\u0158e\u0161en\u00ed:\n",
                "- vym\u011bnit objektiv za \u0161ir\u0161\u00ed\n",
                "- uzav\u0159\u00edt clonu\n",
                "\n",
                "### Chromatick\u00e1 aberace\n",
                "barevn\u00e9 lemov\u00e1n\u00ed hran\n",
                "\n",
                "P\u0159\u00ed\u010diny:\n",
                "- konstrukce \u010do\u010dky objektivu\n",
                "- p\u0159\u00edli\u0161 **otev\u0159en\u00e1** clona\n",
                "\n",
                "\u0158e\u0161en\u00ed:\n",
                "- vym\u011bnit objektiv (jin\u00fd materi\u00e1l \u010do\u010dky, men\u0161\u00ed zoom)\n",
                "- uzav\u0159\u00edt clonu\n",
                "\n",
                "### Difrakce\n",
                "sn\u00ed\u017een\u00ed ostrosti obrazu, zrnitost\n",
                "- obecn\u00fd probl\u00e9m pr\u016fchodu vln\u011bn\u00ed \u00fazkou \u0161t\u011brbinou\n",
                "- [Difrakce (Wikipedia)](https://cs.wikipedia.org/wiki/Difrakce)\n",
                "\n",
                "P\u0159\u00ed\u010diny:\n",
                "- p\u0159\u00edli\u0161 **uzav\u0159en\u00e1** clona\n",
                "\n",
                "\u0158e\u0161en\u00ed:\n",
                "- nastavit clonu na **sweet-spot** (omezen\u00ed v\u0161ech vad optiky)\n",
                "\n",
                "### Distorze\n",
                "Zak\u0159iven\u00ed \u010dar, kter\u00e9 jsou v realit\u011b rovn\u00e9\n",
                "- zejm\u00e9na u **\u0161iroko\u00fahl\u00fdch objektiv\u016f**\n",
                "- **radi\u00e1ln\u00ed** distorze... barrel/pincushion\n",
                "- **tangenci\u00e1ln\u00ed**... \"naklon\u011bn\u00ed\" obrazu, jedna strana bl\u00ed\u017ee ne\u017e druh\u00e1\n",
                "\n",
                "\u0158e\u0161en\u00ed:\n",
                "- v\u00fdm\u011bna objektivu\n",
                "- digit\u00e1ln\u00ed **kalibrace** obrazu\n",
                "\n",
                "Kalibrace:\n",
                "- na z\u00e1klad\u011b sn\u00edmk\u016f referen\u010dn\u00edho obrazu (\u0161achovnice zn\u00e1m\u00fdch rozm\u011br\u016f)\n",
                "- ztr\u00e1tov\u00e1... od\u0159\u00edznut\u00ed zak\u0159iven\u00e9ho obrazu v kraj\u00edch\n",
                "- form\u00e1ln\u011b... nalezen\u00ed kalibra\u010dn\u00edch parametr\u016f\n",
                "- $k_{1:3}$ pro radi\u00e1ln\u00ed\n",
                "- $p_{1:2}$ pro tangenci\u00e1ln\u00ed"
            ],
            "id": "2ee8529d3603460c"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": [
                "# Kalibrace kamery\n",
                "- Nafotit 10-20 fotek \u0161achovnice z r\u016fzn\u00fdch \u00fahl\u016f a v r\u016fzn\u00fdch \u010d\u00e1stech obrazu.\n",
                "- Zkalibrovat."
            ],
            "id": "d6de762367b69a55"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": [
                "\n",
                "- Velikost \u0161achovnice: Velikost \u0161achovnice by m\u011bla b\u00fdt zvolena tak, aby p\u0159i po\u017eadovan\u00e9 pracovn\u00ed vzd\u00e1lenosti zab\u00edrala alespo\u0148 50% sn\u00edmku p\u0159i pohledu, kdy je \u0161achovnice paraleln\u011b se sn\u00edma\u010dem (fronto-paraleln\u011b).\n",
                "- Nato\u010den\u00ed vzoru: Pro zji\u0161t\u011bn\u00ed distorzn\u00edch parametr\u016f by m\u011bly posta\u010dit pouze fronto-paraleln\u00ed sn\u00edmky \u0161achovnice. Pro zji\u0161t\u011bn\u00ed vnit\u0159n\u00edch parametr\u016f je zapot\u0159eb\u00ed vzor nat\u00e1\u010det v r\u016fzn\u00fdch \u00fahlech. Doporu\u010den\u00e9 nato\u010den\u00ed je +- 45\u00b0 okolo vertik\u00e1ln\u00ed a horizont\u00e1ln\u00ed osy. I v p\u0159\u00edpad\u011b, \u017ee chceme zjistit pouze distorzn\u00ed parametry, je vhodn\u00e9 nat\u00e1\u010det vzor v r\u016fzn\u00fdch \u00fahlech a vytvo\u0159it v\u011bt\u0161\u00ed dataset.\n",
                "- Rozlo\u017een\u00ed sn\u00edmk\u016f: Mus\u00edme vzor um\u00edstit do v\u0161ech \u010d\u00e1st\u00ed sn\u00edmku. Pokud nebudeme m\u00edt nap\u0159. vzor na okraj\u00edch, parametry nebudou dostate\u010dn\u011b sv\u00e1z\u00e1ny (constrained).\n",
                "- Filtrace sn\u00edmk\u016f: Po samotn\u00e9 kalibrac\u00ed je vhodn\u00e9 prov\u00e9st filtraci sn\u00edmk\u016f. \u010casto nekvalitn\u00ed sn\u00edmky mohou zhor\u0161it v\u00fdsledky kalibrace a jejich reproje\u010dn\u00ed chyba je vy\u0161\u0161\u00ed ne\u017e u ostatn\u00edch sn\u00edmk\u016f. N\u00e1sledn\u011b je mo\u017en\u00e9 po\u0159\u00eddit sn\u00edmek znovu a op\u011btovn\u011b prov\u00e9st kalibraci.\n",
                "- Overfitting: N\u00edzk\u00e1 reprojek\u010dn\u00ed chyba neznamen\u00e1 nutn\u011b dobrou kalibraci. M\u016f\u017ee se jednat o p\u0159eu\u010den\u00ed (overfitting) modelu na dan\u00fd dataset. Nast\u00e1v\u00e1 p\u0159i pou\u017eit\u00ed p\u0159\u00edli\u0161 flexibiln\u00edho modelu."
            ],
            "id": "65160b34bffb719c"
        },
        {
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2025-01-19T16:31:20.511904Z",
                    "start_time": "2025-01-19T16:31:18.583712Z"
                }
            },
            "cell_type": "code",
            "source": [
                "from improutils import create_file_path, reindex_image_files, camera_calib\n",
                "import yaml\n",
                "\n",
                "def calib1():\n",
                "    calib_folder_path = \"data/calibration\"\n",
                "\n",
                "    reindex_image_files(calib_folder_path)\n",
                "    images_format = '%01d.bmp'\n",
                "\n",
                "    calibration_file_name = \"calibration.yaml\" ### *.yaml\n",
                "    output_calib_file_path = create_file_path(calib_folder_path, calibration_file_name)\n",
                "\n",
                "    chess_shape = (9, 6)  # po\u010det roh\u016f mezi \u010dtverci \u0161achovnice, ignoruje jednu \u0159adu \u010dtverc\u016f od ka\u017ed\u00e9ho kraje\n",
                "\n",
                "    input_source = create_file_path(calib_folder_path, images_format)\n",
                "    camera_matrix, dist_coefs, good_images = camera_calib(input_source=input_source, chess_shape=chess_shape,output_calib_file=output_calib_file_path) ###"
            ],
            "id": "1a01591523c6ee1f",
            "outputs": [],
            "execution_count": 2
        },
        {
            "metadata": {},
            "cell_type": "raw",
            "source": [
                "from improutils import plot_images\n",
                "\n",
                "def calib2():\n",
                "    chess_shape = (9,6) ### tuple\n",
                "    calib_folder_path = './calib_photos' ###\n",
                "    reprojection_error, camera_matrix, dist_coeffs, _, _, std_deviations_intrinsics, _, per_view_errors, chessboard_images = camera_calibration(calib_folder_path, chess_shape) ###\n",
                "\n",
                "    detected_images = list(chessboard_images.values())\n",
                "    plot_images(*detected_images[0:]) ###\n",
                "\n",
                "    detected_image_names = list(chessboard_images.keys())\n",
                "    pixel_size = 0.00000586 ### use cameras datasheet to find pixel size\n",
                "    calibration_stats(reprojection_error, camera_matrix, dist_coeffs, std_deviations_intrinsics, per_view_errors, detected_image_names, pixel_size) ###\n",
                "\n",
                "    img_corrected = correct_frame(img_distorsion, camera_matrix, dist_coeffs) ###\n",
                "\n",
                "    plot_images(img_distorsion, img_corrected) ###"
            ],
            "id": "e60ea3a5cd7f763c"
        },
        {
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2025-01-19T16:31:20.549932Z",
                    "start_time": "2025-01-19T16:31:20.547990Z"
                }
            },
            "cell_type": "code",
            "source": [
                "def correct_frame(frame, camera_matrix, dist_coeffs):\n",
                "    \"\"\"Returns undistorted frame.\"\"\"\n",
                "    return cv2.undistort(frame, camera_matrix, dist_coeffs)"
            ],
            "id": "68cb5fcfde44c5df",
            "outputs": [],
            "execution_count": 3
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": [
                "# M\u011b\u0159en\u00ed d\u00edlu\n",
                "- Nafotit d\u00edl (s referen\u010dn\u00edm objektem)\n",
                "- Zm\u011b\u0159it d\u00edl"
            ],
            "id": "8e486d26203e3ae9"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": [
                "\n",
                "Relevatntn\u00ed funkce:\n",
                "- `segmentation_two_thresholds`\n",
                "- `segmentation_auto_threshold`\n",
                "- `segmentation_adaptive_threshold`\n",
                "- `segmentation_auto_threshold`\n",
                "\n",
                "Hled\u00e1n\u00ed kontury:\n",
                "- `cv2.dilate` [doc](https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html)\n",
                "- `cv2.erode`\n",
                "- `fill_holes`\n",
                "- `find_contours` -> `(contour_drawn: np.ndarray, count: int, contours: list)`\n",
                "\n",
                "`enum_contours` (hw01) !\n",
                "\n",
                "P\u0159evod na geometrick\u00fd \u00fatvar:\n",
                "- `cv2.minAreaRect` -> `(center(x, y), (width, height), angle of rotation)` [guide](https://theailearner.com/tag/cv2-minarearect/)\n",
                "- `cv2.boundingRect` kolm\u00fd na osy x, y\n",
                "- `cv2.minEnclosingCircle` -> `(center, radius)`"
            ],
            "id": "a8ca3815353b7e9e"
        },
        {
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2025-01-19T16:31:20.581853Z",
                    "start_time": "2025-01-19T16:31:20.554698Z"
                }
            },
            "cell_type": "code",
            "source": [
                "import improutils\n",
                "from improutils import apply_mask\n",
                "from ipywidgets import interact, interactive, fixed, interact_manual  # slidery na segmentaci\n",
                "\n",
                "def slider():\n",
                "    # Grayscale/na jedn\u00e9 barv\u011b\n",
                "    img = load_image('images/basic.png')\n",
                "    @interact(threshold_range=create_slider(min=0, max=255, description='Threshold range:',))\n",
                "    def _(threshold_range):\n",
                "        mask = improutils.segmentation_two_thresholds(img, threshold_range[0], threshold_range[1])\n",
                "        plot_images(mask)\n",
                "    # HSV\n",
                "    @interact(h_range=create_slider(min=0, max=360, description='Hue:'),\n",
                "              s_range=create_slider(min=0, max=255, description='Saturation:'),\n",
                "              v_range=create_slider(min=0, max=255, description='Value:'))\n",
                "    def _(h_range, s_range, v_range):\n",
                "\n",
                "        lower_bound = (improutils.to_intensity(h_range[0]), s_range[0], v_range[0])\n",
                "        upper_bound = (improutils.to_intensity(h_range[1]), s_range[1], v_range[1])\n",
                "\n",
                "        mask = improutils.segmentation_two_thresholds(img, lower_bound, upper_bound)\n",
                "        plot_images(mask, apply_mask(img, mask))"
            ],
            "id": "34eb9a5963f38d75",
            "outputs": [],
            "execution_count": 4
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": [
                "# Freestyle"
            ],
            "id": "cb5aae0c846c6324"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": [
                "### General\n",
                "#### Popisn\u00e9 charakteristiky\n",
                "def form_factor(contour):\n",
                "def roundness(contour):\n",
                "def aspect_ratio(contour):\n",
                "def convexity(contour):\n",
                "def solidity(contour):\n",
                "def compactness(contour):\n",
                "def extent(contour):\n",
                "\n",
                "- Formfactor (\u0161pi\u010datost)\n",
                "- Roundness (kulatost)\n",
                "- Aspect Ratio (pom\u011br stran)\n",
                "- Convexity (konvexita, vypouklost)\n",
                "- Solidity (plnost, celistvost)\n",
                "- Compactness (kompaktnost, hutnost)\n",
                "- Extent (dosah, rozm\u011brnost)\n"
            ],
            "id": "b9df7b28e6f64f45"
        },
        {
            "metadata": {},
            "cell_type": "raw",
            "source": [
                "def segment_object(image, background):\n",
                "    image_negative = improutils.negative(image[...,2])\n",
                "    image_masked = improutils.apply_mask(image_negative, mask)\n",
                "    cont_drawn, _, contours = improutils.find_contours(apply_mask(neg, mask), 1000)\n",
                "    cont = contours[0]\n",
                "\n",
                "    binary_object_cropped = improutils.crop_by_bounding_rect(cont_drawn)\n",
                "\n",
                "    return binary_object_cropped, cont\n",
                "\n",
                "image = improutils.load_image(\"data/object.bmp\")\n",
                "background = improutils.load_image(\"data/background.bmp\")\n",
                "mask = improutils.segmentation_one_threshold(background[...,2], 128)  # red channel in BGR ... red backlight\n",
                "\n",
                "binary_object, cont = segment_object(image, mask)\n",
                "plot_images(binary_object)\n",
                "\n",
                "functions = [improutils.form_factor, improutils.roundness, improutils.aspect_ratio, improutils.convexity,\n",
                "            improutils.solidity, improutils.compactness, improutils.extent]\n",
                "\n",
                "shape_descriptions = list()\n",
                "\n",
                "for func in functions:\n",
                "    shape_descriptions.append(func(cont))\n",
                "\n",
                "# Konverze do np.array form\u00e1tu\n",
                "shape_descriptions = np.array(shape_descriptions)"
            ],
            "id": "ea9e88aaa52b5272"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": [
                "### Some usage examples"
            ],
            "id": "491a704e0c997946"
        },
        {
            "metadata": {},
            "cell_type": "raw",
            "source": [
                "# Aplikace Cannyho detektoru\n",
                "\n",
                "image_edges = cv2.blur(image, (3, 3))\n",
                "\n",
                "# Canny(image, threshold1, threshold2[, edges[, apertureSize[, L2gradient]]]) -> edges\n",
                "image_edges = cv2.Canny(image_edges, 200, 250)\n",
                "\n",
                "plot_images(image_edges)\n",
                "\n",
                "# Aplikace Houghovy transformace\n",
                "\n",
                "# HoughLinesP(image, rho, theta, threshold[, lines[, minLineLength[, maxLineGap]]]) -> lines\n",
                "linesP = cv2.HoughLinesP(image_edges, 1, np.pi / 2 - .025, 100, None, 300, 20)\n",
                "image_lines = draw_lines(image_edges, linesP)  # kreslen\u00ed\n",
                "\n",
                "plot_images(image_lines)"
            ],
            "id": "f949aa0d93558d10"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": [
                "### Perspektiva"
            ],
            "id": "cc76c358d3dedc2a"
        },
        {
            "metadata": {},
            "cell_type": "raw",
            "source": [
                "# nalezen\u00e9 z improutils.show_images\n",
                "src_pts = np.array([(47, 1013), (195, 128), (1316, 356), (1191, 1127)]) # np.array of tuples\n",
                "\n",
                "# A4 pap\u00edr NA \u0160\u00cd\u0158KU... 210 x 297 mm\n",
                "dst_pts = np.array([(0, 2100), (0, 0), (2970, 0), (2970, 2100)]) # np.array of tuples\n",
                "\n",
                "H, mask = cv2.findHomography(src_pts, dst_pts)\n",
                "print(H, H.shape)\n",
                "\n",
                "warped_img = cv2.warpPerspective(img, H, (2970, 2100))  # p\u0159ekrout\u00ed cel\u00fd obr\u00e1zek\n",
                "plot_images(warped_img)\n",
                "\n",
                "point = np.array([[(346, 754)]], dtype='float32')  # bod z p\u016fvodn\u00edho obr\u00e1zku\n",
                "point_t = cv2.perspectiveTransform(point, H)  # p\u0159ekrout\u00ed jeden bod\n",
                "\n",
                "\n",
                "# moje pouziti v ukolu\n",
                "H, status = cv2.findHomography(temp_pts, orig_pts, cv2.RANSAC, 50.0)\n",
                "\n",
                "line_start = np.array([[(111,276)]], dtype='float32')\n",
                "line_end =  np.array([[(374,270)]], dtype='float32')\n",
                "\n",
                "line_start_t = cv2.perspectiveTransform(line_start,H )\n",
                "line_end_t = cv2.perspectiveTransform(line_end, H)\n",
                "\n",
                "dist = np.linalg.norm(line_start_t - line_end_t)\n",
                "print(f'\u0160\u00ed\u0159ka v pixelech = {dist:.02f}')\n",
                "\n",
                "# 8.5cm d\u00e9lka Raspberry PI model 2 (model B)\n",
                "cm_per_pixel = 8.5/dist\n",
                "cm_per_pixel_sq = (cm_per_pixel**2)\n",
                "\n",
                "for i,cnt in enumerate(cnts):\n",
                "    area_pixels = cv2.contourArea(cnt)\n",
                "    area = area_pixels * cm_per_pixel_sq\n",
                "    print(f\"Plocha pro mikro\u010dip {i + 1}: {area:.2f} cm\u00b2\")"
            ],
            "id": "32630d630a4dd139"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": [
                "### Helper functions"
            ],
            "id": "d84fb12f3d7b9f5b"
        },
        {
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2025-01-19T16:31:20.591260Z",
                    "start_time": "2025-01-19T16:31:20.588947Z"
                }
            },
            "cell_type": "code",
            "source": [
                "def describe_img(img: np.ndarray) -> None:\n",
                "    resolution = img.shape[:2] ###\n",
                "    print(f'Rozli\u0161en\u00ed obrazu:          {img.shape[:2] = }')\n",
                "\n",
                "    number_of_channels = img.shape[2] ###\n",
                "    print(f'Po\u010det kan\u00e1l\u016f:              {img.shape[2] = }')\n",
                "\n",
                "    # np.min == np.amin != np.maximum\n",
                "    print(f'Nejni\u017e\u0161\u00ed hodnota v obrazu: {np.min(img) = }')\n",
                "    print(f'Nevy\u0161\u0161\u00ed hodnota v obrazu:  {np.max(img) = }')\n",
                "    print(f'Pr\u016fm\u011brn\u00e1 hodnota obrazu:   {np.mean(img) = }')\n",
                "\n",
                "    print(f'Rozli\u0161en\u00ed v MPix:          {resolution[0] * resolution[1] / (10 ** 6) = }')"
            ],
            "id": "cb165b7780f0dd95",
            "outputs": [],
            "execution_count": 5
        },
        {
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2025-01-19T16:31:20.597812Z",
                    "start_time": "2025-01-19T16:31:20.595613Z"
                }
            },
            "cell_type": "code",
            "source": [
                "def describe_contour(contour: np.ndarray) -> None:\n",
                "    area = cv2.contourArea(contour) ###\n",
                "    print(f'Obsah kontury:             {area = }')\n",
                "\n",
                "    perimeter = cv2.arcLength(contour, True) ###\n",
                "    print(f'Obvod kontury:             {perimeter = }')\n",
                "\n",
                "    rect = cv2.minAreaRect(contour)\n",
                "    shape_width, shape_height = rect[1]\n",
                "\n",
                "    center = cv2.moments(contour) ###\n",
                "    center_x = int(center[\"m10\"] / center[\"m00\"])\n",
                "    center_y = int(center[\"m01\"] / center[\"m00\"])\n",
                "    print(f'St\u0159ed kontury:             {(center_x, center_y) = }')"
            ],
            "id": "e924ae3f6b4a3eb8",
            "outputs": [],
            "execution_count": 6
        },
        {
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2025-01-19T16:31:20.603867Z",
                    "start_time": "2025-01-19T16:31:20.602107Z"
                }
            },
            "cell_type": "code",
            "source": [
                "def angle_lines(line1, line2):\n",
                "    x1, y1, x2, y2 = line1\n",
                "    x3, y3, x4, y4 = line2\n",
                "\n",
                "    angle1 = math.atan2(y1 - y2, x1 - x2)\n",
                "    angle2 = math.atan2(y3 - y4, x3 - x4)\n",
                "\n",
                "    return math.degrees(angle1 - angle2)"
            ],
            "id": "8070abab7bc789fa",
            "outputs": [],
            "execution_count": 7
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": [
                "### HW01"
            ],
            "id": "dc3afbc03e514f09"
        },
        {
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2025-01-19T16:31:20.620976Z",
                    "start_time": "2025-01-19T16:31:20.610509Z"
                }
            },
            "cell_type": "code",
            "source": [
                "import math\n",
                "import itertools\n",
                "from improutils import to_intensity, segmentation_two_thresholds, find_contours, load_image, crop, to_hsv, plot_images\n",
                "\n",
                "\n",
                "def hw01():\n",
                "    # na\u010dten\u00ed obrazu\n",
                "    img = load_image('images/basic.png')\n",
                "    img = crop(img, 440, 200, 1600, 900)\n",
                "    img_hsv = to_hsv(img)\n",
                "    plot_images(img,img_hsv)\n",
                "    # segmentace obd\u00e9ln\u00edk\u016f\n",
                "    lower_bound = (to_intensity(18), 140, 149)\n",
                "    upper_bound = (to_intensity(64), 255, 201)\n",
                "\n",
                "    lower_bound_other = (to_intensity(314), 113, 0)\n",
                "    upper_bound_other = (to_intensity(360), 255, 255)\n",
                "\n",
                "    rect_others = segmentation_two_thresholds(img_hsv, lower_bound_other, upper_bound_other) ### prahy pro segmentaci v RGB\n",
                "    rect_ref = segmentation_two_thresholds(img_hsv, lower_bound, upper_bound) ### prahy pro segmentaci v RGB\n",
                "    rect_mask = cv2.add(rect_others, rect_ref)\n",
                "\n",
                "    # nalezen\u00ed referen\u010dn\u00edho obd\u00e9ln\u00edku podle velikosti kontury\n",
                "    drawn_ref, _, ref_cnt = find_contours(rect_mask, 30000, 85000)\n",
                "\n",
                "    # nalezen\u00ed kontur v\u0161ech obd\u00e9ln\u00edk\u016f\n",
                "    drawn_ref_others, _, ref_cnt_others = find_contours(rect_mask, 10000)\n",
                "\n",
                "    ref_width_real = 40\n",
                "    ref_height_real = 80\n",
                "\n",
                "    # vypo\u010dten\u00ed pom\u011bru mm/pix\n",
                "    rect = cv2.minAreaRect(ref_cnt[0])\n",
                "    ref_width_image, ref_height_image = rect[1]\n",
                "    real_image_ratio = min(ref_width_real, ref_height_real) / min(ref_width_image, ref_height_image)\n",
                "\n",
                "    print(f'Recalculated size: {(ref_width_image*real_image_ratio, ref_height_image*real_image_ratio)}')\n",
                "    print(f'Ratio between real width and image width: {real_image_ratio}')\n",
                "\n",
                "\n",
                "    def get_bounding_rect_center(contour):\n",
                "        x, y, w, h = cv2.boundingRect(contour)\n",
                "        center_x = x + w // 2\n",
                "        center_y = y + h // 2\n",
                "        return (center_x, center_y)\n",
                "    contours = ref_cnt_others\n",
                "    contours = sorted(contours, key=lambda c: (get_bounding_rect_center(c)[0], get_bounding_rect_center(c)[1]))\n",
                "\n",
                "    contour_images = []\n",
                "\n",
                "    for contour in contours:\n",
                "        contour_images.append(img.copy())\n",
                "        cv2.drawContours(contour_images[-1], [contour], -1, color=(0, 255, 0 ), thickness=5)\n",
                "\n",
                "    plot_images(*contour_images,titles=[0,1,2,3,4],title_size=64)\n",
                "\n",
                "    index_list = list(range(len(contours)))\n",
                "    combinations = list(itertools.combinations(index_list , 2))\n",
                "\n",
                "    def line_segment_to_point_dist(l_pt1, l_pt2, dst_pt,ret_points=False):\n",
                "        x1, y1 = l_pt1\n",
                "        x2, y2 = l_pt2\n",
                "        x0, y0 = dst_pt\n",
                "\n",
                "        # Umocn\u011bn\u00e1 velikost \u00fase\u010dky\n",
                "        line_len_sq = (x2 - x1) ** 2 + (y2 - y1) ** 2\n",
                "\n",
                "        # Projek\u010dn\u00ed faktor\n",
                "        t = ((x0 - x1) * (x2 - x1) + (y0 - y1) * (y2 - y1)) / line_len_sq\n",
                "\n",
                "        # Ur\u010d\u00edme vzd\u00e1lenosti od bodu [x0,y0] v\u016f\u010di r\u016fzn\u00fdm situac\u00edm\n",
                "        if t < 0:\n",
                "            # Vzd\u00e1lenost od bodu [x1,y1]\n",
                "            proj_x = x1\n",
                "            proj_y = y1\n",
                "        elif t > 1:\n",
                "            # Vzd\u00e1lenost od bodu [x2,y2]\n",
                "            proj_x = x2\n",
                "            proj_y = y2\n",
                "        else:\n",
                "            # Vzd\u00e1lenost kolmice na \u00fase\u010dku\n",
                "            proj_x = x1 + t * (x2 - x1)\n",
                "            proj_y = y1 + t * (y2 - y1)\n",
                "\n",
                "        if ret_points:\n",
                "            return math.sqrt((x0 - proj_x) ** 2 + (y0 - proj_y) ** 2), [(x0,y0), [proj_x, proj_y]]\n",
                "        # Spo\u010dteme vzd\u00e1lenost\n",
                "        return math.sqrt((x0 - proj_x) ** 2 + (y0 - proj_y) ** 2)\n",
                "\n",
                "    def line_segments_dist(l1_pt1, l1_pt2, l2_pt1, l2_pt2, ret_points = False):\n",
                "        # V\u017edy 2 mo\u017enosti bodu pro jednu \u00fase\u010dku\n",
                "        distances = [\n",
                "            line_segment_to_point_dist(l1_pt1, l1_pt2, l2_pt1,ret_points),\n",
                "            line_segment_to_point_dist(l1_pt1, l1_pt2, l2_pt2,ret_points),\n",
                "            line_segment_to_point_dist(l2_pt1, l2_pt2, l1_pt1,ret_points),\n",
                "            line_segment_to_point_dist(l2_pt1, l2_pt2, l1_pt2,ret_points)\n",
                "        ]\n",
                "\n",
                "        if not ret_points:\n",
                "            return min(distances)\n",
                "\n",
                "        min_distance, closest_points = min(distances, key=lambda x: x[0])\n",
                "\n",
                "        return min_distance, closest_points\n",
                "\n",
                "    def rect_dist(r1_pts, r2_pts, ret_points=False):\n",
                "        # Obd\u00e9ln\u00edk je tvo\u0159en 4 \u00fase\u010dkami\n",
                "        r1_segments = [\n",
                "            (r1_pts[0], r1_pts[1]),\n",
                "            (r1_pts[1], r1_pts[2]),\n",
                "            (r1_pts[2], r1_pts[3]),\n",
                "            (r1_pts[3], r1_pts[0])\n",
                "        ]\n",
                "\n",
                "        r2_segments = [\n",
                "            (r2_pts[0], r2_pts[1]),\n",
                "            (r2_pts[1], r2_pts[2]),\n",
                "            (r2_pts[2], r2_pts[3]),\n",
                "            (r2_pts[3], r2_pts[0])\n",
                "        ]\n",
                "        closest_pts = None\n",
                "\n",
                "        # Najdeme nejmen\u0161\u00ed vzd\u00e1lenost mezi libovolnou \u00fase\u010dkou r1 a libovolnou \u00fase\u010dkou r2\n",
                "        min_distance = float('inf')\n",
                "        for seg1 in r1_segments:\n",
                "            for seg2 in r2_segments:\n",
                "                dist = line_segments_dist(seg1[0], seg1[1], seg2[0], seg2[1],ret_points)\n",
                "                if ret_points and dist[0] < min_distance:\n",
                "                    closest_pts = dist[1]\n",
                "                    min_distance = dist[0]\n",
                "                elif not ret_points and dist < min_distance:\n",
                "                    min_distance = dist\n",
                "\n",
                "        if ret_points:\n",
                "            return min_distance, closest_pts\n",
                "        else:\n",
                "            return min_distance\n",
                "\n",
                "    rectangles = [cv2.boxPoints(cv2.minAreaRect(cnt)) for cnt in contours]\n",
                "\n",
                "    for comb in combinations:\n",
                "        idx1, idx2 = comb\n",
                "\n",
                "        r1_pts = rectangles[idx1]\n",
                "        r2_pts = rectangles[idx2]\n",
                "\n",
                "        dist_px = rect_dist(r1_pts, r2_pts)\n",
                "\n",
                "        print(f\"{idx1} <-> {idx2}: {dist_px * real_image_ratio / 10:.2f} cm\")\n",
                "\n",
                "\n",
                "    image = img.copy()\n",
                "\n",
                "    for comb in combinations:\n",
                "        idx1, idx2 = comb\n",
                "        r1_pts = rectangles[idx1]\n",
                "        r2_pts = rectangles[idx2]\n",
                "\n",
                "        dist_px, (pt1, pt2) = rect_dist(r1_pts, r2_pts, True)\n",
                "\n",
                "        pt1, pt2 = map(tuple, map(lambda pt: map(int, pt), (pt1, pt2)))\n",
                "\n",
                "        dist_cm = dist_px * real_image_ratio / 10\n",
                "        cv2.line(image, pt1, pt2, color=(255, 0, 0), thickness=2)\n",
                "\n",
                "    # Rozd\u011blen\u00e9 abych text vypsal p\u0159es \u010d\u00e1ry\n",
                "    for comb in combinations:\n",
                "        idx1, idx2 = comb\n",
                "        r1_pts = rectangles[idx1]\n",
                "        r2_pts = rectangles[idx2]\n",
                "\n",
                "        dist_px, (pt1, pt2) = rect_dist(r1_pts, r2_pts, True)\n",
                "\n",
                "        pt1, pt2 = map(tuple, map(lambda pt: map(int, pt), (pt1, pt2)))\n",
                "        position = tuple(map(int, ((pt1[0] + pt2[0]) / 2 - 30, (pt1[1] + pt2[1]) / 2 - 20)))\n",
                "\n",
                "        dist_cm = dist_px * real_image_ratio / 10\n",
                "        cv2.putText(image, f'{dist_cm:.2f}cm'.format(\".2f\"), position, cv2.FONT_HERSHEY_COMPLEX, 0.65, (255, 255, 255), 2, cv2.LINE_AA)"
            ],
            "id": "2234cef9ce25f5",
            "outputs": [],
            "execution_count": 8
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": [
                "## library.ipynb"
            ],
            "id": "a8f408b16913ace7"
        },
        {
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2025-01-19T16:31:20.625914Z",
                    "start_time": "2025-01-19T16:31:20.623825Z"
                }
            },
            "cell_type": "code",
            "source": [
                "def rotate_image(image, angle, image_center=None):\n",
                "    \"\"\" Rotates the input image by specified angle.\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    image : np.ndarray\n",
                "        Image to be rotated.\n",
                "    angle : float\n",
                "        Rotation angle.\n",
                "    image_center : Optional[tuple(int, int)]\n",
                "        Center of rotation.\n",
                "    Returns\n",
                "    -------\n",
                "    np.ndarray\n",
                "        Returns the rotated input image by specified angle.\n",
                "    \"\"\"\n",
                "    if image_center is None:\n",
                "        image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
                "    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
                "    result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
                "    return result"
            ],
            "id": "c417a9c9d8f11b0b",
            "outputs": [],
            "execution_count": 9
        },
        {
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2025-01-19T16:31:20.632482Z",
                    "start_time": "2025-01-19T16:31:20.630085Z"
                }
            },
            "cell_type": "code",
            "source": [
                "from improutils import copy_to\n",
                "\n",
                "\n",
                "def draw_rotated_text(img, text, point, angle, text_scale, text_color, text_thickness):\n",
                "    img_filled = np.full(img.shape, text_color, dtype=np.uint8)\n",
                "    # create rotated text mask\n",
                "    text_mask = np.zeros((img.shape[0], img.shape[1]), dtype=np.uint8)\n",
                "    cv2.putText(text_mask, \"{:.2f} cm\".format(text), point, 0, text_scale, (255, 255, 255), text_thickness)\n",
                "    if angle > 0:\n",
                "        angle = -angle + 90\n",
                "    elif angle < 0:\n",
                "        angle = angle + 90\n",
                "    text_mask = rotate_image(text_mask, -angle, point)\n",
                "    result = copy_to(img_filled, img.copy(), text_mask)\n",
                "    return result"
            ],
            "id": "a1b42d82f2d1455d",
            "outputs": [],
            "execution_count": 10
        },
        {
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2025-01-19T16:31:20.644341Z",
                    "start_time": "2025-01-19T16:31:20.639238Z"
                }
            },
            "cell_type": "code",
            "source": [
                "from ipywidgets import interact, interactive, fixed, interact_manual\n",
                "import ipywidgets as widgets\n",
                "import ipywidgets as widgets\n",
                "from IPython.display import display\n",
                "\n",
                "def create_slider(min, max, description):\n",
                "    description = description.ljust(30, '\\xa0')\n",
                "    return widgets.IntRangeSlider( min=min, max=max, step=1,value=[min,max],\n",
                "                                   description=description,\n",
                "                                   continuous_update=False,\n",
                "                                   orientation='horizontal',\n",
                "                                   style=dict(description_width='initial'),\n",
                "                                   layout=widgets.Layout(width='auto'),\n",
                "                                   )\n",
                "\n",
                "def multicolor_segmentation(func,colors):\n",
                "    \"\"\" Allows interactive HSV thresholding for multiple colors with saving and returning thresholds that are picked by the user.\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    func : function\n",
                "        function with arguments hue = h_range (int, range: 0-360), saturation = s_range (int, range: 0-255), value = v_range (int, range: 0-255)\n",
                "    colors : list\n",
                "        list of colors that the user can choose from, e.g. ['red', 'green', 'blue'], these colors will be used as keys in the output dictionary\n",
                "    Returns\n",
                "    -------\n",
                "    color_thresholds: dict\n",
                "        Returns a dictionary with the chosen thresholds for each color, e.g. {'red': (0, 0, 0), 'green': (0, 0, 0), 'blue': (0, 0, 0)}, can be also empty if no thresholds were saved\n",
                "    \"\"\"\n",
                "    color_thresholds = {}\n",
                "\n",
                "    # initialize sliders, buttons etc.\n",
                "    h_slider=create_slider(min=0, max=360, description='Hue:')\n",
                "    s_slider=create_slider(min=0, max=255, description='Saturation:')\n",
                "    v_slider=create_slider(min=0, max=255, description='Value:')\n",
                "\n",
                "    color_dropdown = widgets.Dropdown(options=colors, description='Color:'.ljust(30, '\\xa0'), style ={'description_width': 'initial'},layout = {'width': 'max-content'})\n",
                "\n",
                "    save_button = widgets.Button(description='Save threshold for color',layout=widgets.Layout(width='auto'),button_style='success')\n",
                "    finish_button = widgets.Button(description='Return saved thresholds',layout=widgets.Layout(width='auto'),button_style='danger')\n",
                "\n",
                "    text_output = widgets.Output()\n",
                "    interactive_output = widgets.interactive_output(func,{'h_range':h_slider,'s_range':s_slider,'v_range':v_slider})\n",
                "\n",
                "    # widget layout\n",
                "    input_box = widgets.VBox([h_slider,s_slider,v_slider,color_dropdown])\n",
                "    button_box = widgets.HBox([save_button, finish_button])\n",
                "    other_box = widgets.VBox([text_output, interactive_output])\n",
                "\n",
                "    def reset_sliders():\n",
                "        h_slider.value = (0,360)\n",
                "        s_slider.value = (0,255)\n",
                "        v_slider.value = (0,255)\n",
                "\n",
                "    # button callbacks\n",
                "    def on_save_clicked(b):\n",
                "        with text_output:\n",
                "            text_output.clear_output()\n",
                "            color_thresholds[color_dropdown.value] = (h_slider.value, s_slider.value, v_slider.value)\n",
                "            print(f\"Saved for color '{color_dropdown.value}', threshold: {color_thresholds[color_dropdown.value]}\\nResetting sliders...\\nChanging to next color...\")\n",
                "            reset_sliders()\n",
                "            # set next color in dropdown\n",
                "            color_dropdown.value = colors[(colors.index(color_dropdown.value)+1)%len(colors)]\n",
                "\n",
                "\n",
                "    def on_finish_clicked(b):\n",
                "        with text_output:\n",
                "            text_output.clear_output()\n",
                "            print('Returned saved thresholds!')\n",
                "            reset_sliders()\n",
                "\n",
                "\n",
                "    save_button.on_click(on_save_clicked)\n",
                "    finish_button.on_click(on_finish_clicked)\n",
                "    # display widget\n",
                "    display(input_box, button_box,other_box)\n",
                "\n",
                "    return color_thresholds"
            ],
            "id": "712674f4cb879e3d",
            "outputs": [],
            "execution_count": 11
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": [
                "## Extra"
            ],
            "id": "e7dc180dcdcd1703"
        },
        {
            "metadata": {},
            "cell_type": "raw",
            "source": [
                "# pomocn\u00e9 funkce z vedlej\u0161\u00edho notebooku se necht\u011bly kamar\u00e1dit (nem\u011bly k dispozici cv2 modul, nech\u00e1pu pro\u010d)\n",
                "\n",
                "def tuple_elems_to_int(t):\n",
                "    '''Converts all values of input tuple to ints.'''\n",
                "    assert len(t) == 2, 'Only tuple with two elements is supported!'\n",
                "    return (int(t[0]), int(t[1]))\n",
                "\n",
                "def kq_of_line_segment(l_p1, l_p2):\n",
                "    '''Computes slope (k) and translation (q) of input line segment defined with two points.'''\n",
                "    a = np.array([[l_p1[0], 1], [l_p2[0], 1]])\n",
                "    b = np.array([l_p1[1], l_p2[1]])\n",
                "\n",
                "    k, q = np.linalg.solve(a, b)\n",
                "\n",
                "    return k, q\n",
                "\n",
                "def normal_kq_in_point(p1, k, q):\n",
                "    '''Computes slope (kn) and translation (qn) of normal (perpendicular) line in point p1.'''\n",
                "    kn = -1/k\n",
                "    qn = p1[1] - kn * p1[0]\n",
                "    return kn, qn\n",
                "\n",
                "def normal_line_start_end_points(point, k, q, dx):\n",
                "    '''Computes pixel points of perpendicular line segment of lenght dx in point point\n",
                "    to line defined by k and q.'''\n",
                "    kn, qn = normal_kq_in_point(point, k, q)\n",
                "\n",
                "    x = [point[0]-dx, point[0]+dx]\n",
                "    y = [kn * x[0] + qn, kn * x[1] + qn]\n",
                "\n",
                "    return (x[0], y[0]), (x[1], y[1])\n",
                "\n",
                "def draw_norm_line_segment_in_point(l_p1, l_p2, point, dx, image):\n",
                "    '''Draws perpendicular line segments to line defined with two points of lenght dx\n",
                "    in point point to input image.'''\n",
                "    k,q = kq_of_line_segment(l_p1, l_p2)\n",
                "    start, end = normal_line_start_end_points(point, k, q, dx)\n",
                "    cv2.line(image, tuple_elems_to_int(start), tuple_elems_to_int(end), (255,255,255), 1, cv2.LINE_4)\n",
                "    return image\n",
                "\n",
                "def draw_contour(image, contour):\n",
                "    '''Draws input contour into image with white color.'''\n",
                "    cv2.drawContours(image, contour, -1, (255,255,255), 1, cv2.LINE_4)\n",
                "    return image"
            ],
            "id": "2e18d859c131e248"
        },
        {
            "metadata": {},
            "cell_type": "raw",
            "source": [
                "img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)  ###\n",
                "vps = compute_vanishing_points(img_rgb)\n",
                "vp1 = vps[0]\n",
                "vp2 = vps[2]\n",
                "vpz = vps[1]  # vertik\u00e1ln\u00ed \u00fab\u011b\u017en\u00edk, v ose pozad\u00ed/sledovan\u00fdch objekt\u016f\n",
                "\n",
                "vl = np.cross(vp1, vp2)\n",
                "REFERENCE_MEASUREMENTS = [\n",
                "    # (bod_na_zemi, bod_ve_vysce, vyska)\n",
                "    ((515, 601), (519, 795), 26.),  ###\n",
                "    ((723, 607), (726, 802), 26.),  ###\n",
                "    ((717, 391), (726, 799), 56.),  ###\n",
                "    ((936, 392), (938, 809), 56.),  ###\n",
                "]\n",
                "\n",
                "# Vytvo\u0159en\u00ed objektu pro v\u00fdpo\u010det odhadu v\u00fd\u0161ky objektu a zavol\u00e1n\u00ed funkce\n",
                "height_estimator = HeightEstimator(REFERENCE_MEASUREMENTS, vl, vpz)\n",
                "height = abs(height_estimator.calc_height(Tx, Bx))\n",
                "\n",
                "# V\u00fdstup\n",
                "print(f'Objekt {height:.2f} mm')\n",
                "## Hloubkov\u00e9 kamery (07)\n"
            ],
            "id": "b0d1f557ecc1a9c0"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": [
                "## library.py"
            ],
            "id": "eda3ae26a2cf2e89"
        },
        {
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2025-01-20T12:39:37.278580Z",
                    "start_time": "2025-01-20T12:39:34.082923Z"
                }
            },
            "cell_type": "code",
            "source": [
                "import cv2\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from typing import List, Tuple, Dict, Union\n",
                "from pathlib import Path\n",
                "from prettytable import PrettyTable\n",
                "from improutils import *\n",
                "\n",
                "def camera_calibration(calib_path: str,\n",
                "                       chess_shape: Tuple[int,int],\n",
                "                       cv2_flags:int = 0,\n",
                "                       extensions: List[str] = [\"jpg\", \"jpeg\" ,\"png\", \"tiff\", \"bmp\"]) -> Tuple[float,\n",
                "np.ndarray,\n",
                "np.ndarray,\n",
                "Tuple[np.ndarray],\n",
                "Tuple[np.ndarray],\n",
                "np.ndarray,\n",
                "np.ndarray,\n",
                "np.ndarray,\n",
                "Dict[str,np.ndarray]]:\n",
                "    \"\"\"Calibrates camera from images with chessboard pattern, using OpenCV's cv2.calibrateCameraExtended function\n",
                "\n",
                "    Args:\n",
                "        calib_path (str): path to the folder containing chessboard pattern images\n",
                "        chess_shape (Tuple[int,int]): interior corner count in the format of rows, columns\n",
                "        cv2_flags (int, optional): additional OpenCV's flags for cv2.calibrateCameraExtended. Defaults to 0.\n",
                "        extensions (List[str], optional): allowed image extensions. Defaults to [\"jpg\", \"jpeg\" ,\"png\", \"tiff\"].\n",
                "\n",
                "    Raises:\n",
                "        ValueError: if calibration images have different sizes\n",
                "        ValueError: if no calibration images were found or could not be read from the provided path\n",
                "        ValueError: if no chessboard patterns were detected in the images\n",
                "\n",
                "    Returns:\n",
                "        Tuple[float, np.ndarray, np.ndarray, Tuple[np.ndarray], Tuple[np.ndarray], np.ndarray, np.ndarray, np.ndarray, Dict[str,np.ndarray]]:\n",
                "        returns the output from cv2.calibrateCameraExtended and dictionary with image names as keys and images with drawn chessboard corners as values\n",
                "    \"\"\"\n",
                "    print(f\"Processing images from {calib_path} with possible extensions {extensions}\")\n",
                "    def correct_extension(path, extensions):\n",
                "        return path.is_file() and path.suffix[1:].lower() in extensions\n",
                "    # termination criteria for subpixel corner detection\n",
                "    # by default it is set to 30 iterations and epsilon = 0.001\n",
                "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
                "\n",
                "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
                "    objp = np.zeros((chess_shape[0] * chess_shape[1], 3), np.float32)\n",
                "    objp[:, :2] = np.mgrid[0:chess_shape[0], 0:chess_shape[1]].T.reshape(-1, 2)\n",
                "\n",
                "    # arrays to store object points and image points from all the images.\n",
                "    objpoints = [] # 3D point in real world space\n",
                "    imgpoints = [] # 2D points in image plane.\n",
                "\n",
                "    image_paths = sorted([path for path in Path(calib_path).glob(\"*\") if correct_extension(path,extensions)])\n",
                "    chess_brd_images = 0\n",
                "    read_images = 0\n",
                "    chessboard_images = {}\n",
                "    img_size = None\n",
                "    for img_path in image_paths:\n",
                "        img_name = img_path.name\n",
                "\n",
                "        img = cv2.imread(img_path)\n",
                "        if img is None:\n",
                "            print(f\"File {img_name} could not be read, skipping...\")\n",
                "            continue\n",
                "        else:\n",
                "            read_images += 1\n",
                "            if img_size is None:\n",
                "                # need to be in the format of width, height\n",
                "                img_size = img.shape[:2][::-1]\n",
                "            else:\n",
                "                if img_size != img.shape[:2][::-1]:\n",
                "                    raise ValueError(\"All images must have same size.\")\n",
                "            print(f\"File {img_name} is being processed...\")\n",
                "\n",
                "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
                "\n",
                "        # find the chess board corners\n",
                "        ret, corners = cv2.findChessboardCorners(gray, chess_shape, None)\n",
                "\n",
                "        # if found, add object points, image points (after refining them)\n",
                "        if ret:\n",
                "            chess_brd_images += 1\n",
                "            print(f\"\\t Corners found!\")\n",
                "            objpoints.append(objp)\n",
                "            subpix_corners = cv2.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
                "            imgpoints.append(subpix_corners)\n",
                "\n",
                "            chessboard_images[img_name] = cv2.drawChessboardCorners(img, chess_shape, subpix_corners, ret)\n",
                "\n",
                "        else:\n",
                "            print(f\"\\t Corners NOT found!\")\n",
                "            continue\n",
                "\n",
                "    print(f\"Number of images with detected chessboard: {chess_brd_images}/{read_images}\")\n",
                "\n",
                "    if read_images == 0:\n",
                "        raise ValueError(\"No images were read from the provided path.\")\n",
                "\n",
                "    if chess_brd_images == 0:\n",
                "        raise ValueError(\"No chessboard patterns were detected in the images.\")\n",
                "\n",
                "    calib_values = cv2.calibrateCameraExtended(objpoints, imgpoints, img_size, cameraMatrix=None, distCoeffs=None, flags=cv2_flags, criteria=criteria)\n",
                "    reprojection_error, camera_matrix, dist_coeffs, rvecs, tvecs, std_deviations_intrinsics, std_deviations_extrinsics, per_view_errors = calib_values\n",
                "    return reprojection_error, camera_matrix, dist_coeffs, rvecs, tvecs, std_deviations_intrinsics, std_deviations_extrinsics, per_view_errors, chessboard_images\n",
                "\n",
                "def calibration_stats(reprojection_error:float,\n",
                "                      camera_matrix: np.ndarray,\n",
                "                      dist_coeffs:np.ndarray,\n",
                "                      std_deviations_intrinsics:np.ndarray=None,\n",
                "                      per_view_errors:np.ndarray=None,\n",
                "                      view_names:List[str]=None,\n",
                "                      pixel_size:Union[float,Tuple[float,float]]=None) -> None:\n",
                "    \"\"\"Prints calibration statistics using.\n",
                "    RMS re-projection error, estimated intrinsics and distortion parameters, standard deviations of intrinsics, focal length in millimeters and per view reprojection errors.\n",
                "\n",
                "    Args:\n",
                "        reprojection_error (float): re-projection error from cv2.calibrateCamera\n",
                "        camera_matrix (np.ndarray): camera matrix from cv2.calibrate\n",
                "        dist_coeffs (np.ndarray): distortion coefficients from cv2.calibrateCamera\n",
                "        std_deviations_intrinsics (np.ndarray, optional): std_deviations_intrinsics from cv2.calibrateCameraExtended. Defaults to None.\n",
                "        per_view_errors (np.ndarray, optional): per_view_errors from cv2.calibrateCameraExtended. Defaults to None.\n",
                "        view_names (List[str], optional): image names for which we detected the chessboard. Defaults to None.\n",
                "        pixel_size (Union[float,Tuple[float,float]], optional): size of physical pixels of a camera in micrometers eg. 4.8 or 5.86 or [5.86, 4.8] for non square pixels. Defaults to None.\n",
                "    \"\"\"\n",
                "    # opencv always returns atleast 4 distortion coefficients\n",
                "    params_amount = 4 + dist_coeffs.shape[1]\n",
                "\n",
                "    parameters = [\"fx\", \"fy\", \"cx\", \"cy\", \"k1\", \"k2\", \"p1\", \"p2\", \"k3\", \"k4\", \"k5\", \"k6\", \"s1\", \"s2\", \"s3\", \"s4\", \"Tx\", \"Ty\"]\n",
                "    units = [\"pixels\"] * 4 + [\"unitless\"] * (params_amount - 4)\n",
                "\n",
                "    print(f\"RMS re-projection error: {reprojection_error:.5f} pixels\")\n",
                "\n",
                "    print(f\"\\nEstimated intrinsics parameters\")\n",
                "    intrinsics_table = PrettyTable()\n",
                "    intrinsics_table.add_column(\"Parameter\", parameters[:4])\n",
                "    intrinsics_table.add_column(\"Estimated Value\", [f\"{val:.5f}\" for val in [camera_matrix[0, 0], camera_matrix[1, 1], camera_matrix[0, 2], camera_matrix[1, 2]]])\n",
                "    intrinsics_table.add_column(\"Unit\", units[:4])\n",
                "    print(intrinsics_table)\n",
                "\n",
                "    print(f\"\\nEstimated Distortion parameters\")\n",
                "    distortion_table = PrettyTable()\n",
                "    distortion_table.add_column(\"Parameter\", parameters[4:params_amount])\n",
                "    distortion_table.add_column(\"Distortion\", [f\"{val:.5f}\" for val in dist_coeffs[0, :params_amount-4]])\n",
                "    distortion_table.add_column(\"Unit\", units[4:params_amount])\n",
                "    print(distortion_table)\n",
                "\n",
                "    if std_deviations_intrinsics is not None:\n",
                "        print(f\"\\nIntrinsic parameters standard deviation\")\n",
                "        intrinsics_std_table = PrettyTable()\n",
                "        intrinsics_std_table.add_column(\"Parameter\", parameters[:params_amount])\n",
                "        intrinsics_std_table.add_column(\"Value\", [f\"\u00b1{val:.5f}\" for val in std_deviations_intrinsics[:params_amount,0]])\n",
                "        intrinsics_std_table.add_column(\"Unit\", units[:params_amount])\n",
                "        print(intrinsics_std_table)\n",
                "\n",
                "    if pixel_size is not None and std_deviations_intrinsics is not None:\n",
                "        if not isinstance(pixel_size, tuple):\n",
                "            pixel_size = (pixel_size, pixel_size)\n",
                "        print(f\"\\nEstimated Focal length in millimeters\")\n",
                "        focal_length_table = PrettyTable()\n",
                "        focal_length_table.add_column(\"Parameter\", parameters[:2])\n",
                "        focal_length_table.add_column(\"Value \u00b1 Std Deviation\", [f\"{val*pix_size/1000:.5f} \u00b1 {std*pix_size/1000:.5f}\" for val, pix_size, std in zip([camera_matrix[0, 0], camera_matrix[1, 1]], pixel_size, std_deviations_intrinsics[:2,0])])\n",
                "        focal_length_table.add_column(\"Unit\", [\"millimeter\"] * 2)\n",
                "        print(focal_length_table)\n",
                "\n",
                "    if per_view_errors is not None:\n",
                "        print(f\"\\nPer view reprojection errors\")\n",
                "        view_error_table = PrettyTable()\n",
                "        # Sort the view names and errors by the errors in descending order\n",
                "        sorted_views_and_errors = sorted(zip(view_names, per_view_errors[:,0]), key=lambda x: x[1], reverse=True)\n",
                "        sorted_view_names, sorted_errors = zip(*sorted_views_and_errors)\n",
                "        view_error_table.add_column(\"Image name\", sorted_view_names)\n",
                "        view_error_table.add_column(\"Re-projection error (sorted)\", [f\"{val:.5f}\" for val in sorted_errors])\n",
                "        view_error_table.add_column(\"Unit\", [\"pixels\"] * len(sorted_view_names))\n",
                "        print(view_error_table)\n",
                "\n",
                "def correct_frame(img, camera_matrix, dist_coeffs):\n",
                "    \"\"\"Returns undistorted image.\"\"\"\n",
                "    return cv2.undistort(img, camera_matrix, dist_coeffs)\n",
                "\n",
                "def _plot_grid(xv, yv, squares, ax):\n",
                "    for i  in np.linspace(0, xv.shape[1] - 1, squares+1, dtype=int):\n",
                "        ax.plot(xv[i,:], yv[i,:], 'k-')\n",
                "    for j in np.linspace(0, xv.shape[0] - 1, squares+1, dtype=int):\n",
                "        ax.plot(xv[:,j], yv[:,j], 'k-')\n",
                "\n",
                "    ax.axis('off')\n",
                "\n",
                "def _radial_distortion(xv, yv, k):\n",
                "    xv_radial = np.zeros_like(xv)\n",
                "    yv_radial = np.zeros_like(yv)\n",
                "    for i in range(xv.shape[0]):\n",
                "        for j in range(xv.shape[1]):\n",
                "            r = np.sqrt(xv[i,j]**2 + yv[i,j]**2)\n",
                "            radial = (1 + (k[0]*(r**2) + k[1]*(r**4) + k[2]*(r**6)))/(1 + (k[3]*(r**2) + k[4]*(r**4) + k[5]*(r**6)))\n",
                "            xv_radial[i,j] = xv[i,j]*radial\n",
                "            yv_radial[i,j] = yv[i,j]*radial\n",
                "    return xv_radial, yv_radial\n",
                "\n",
                "def _tangetial_distortion(xv, yv, p):\n",
                "    xv_tang = np.zeros_like(xv)\n",
                "    yv_tang = np.zeros_like(yv)\n",
                "    for i in range(xv.shape[0]):\n",
                "        for j in range(xv.shape[1]):\n",
                "            x = xv[i,j]\n",
                "            y = yv[i,j]\n",
                "            r = np.sqrt(x**2 + y**2)\n",
                "            x_tang = x + (2*p[0]*x*y + p[1]*(r**2 + 2*x**2))\n",
                "            y_tang = y + (p[0]*(r**2 + 2*y**2) + 2*p[1]*x*y)\n",
                "            xv_tang[i,j] = x_tang\n",
                "            yv_tang[i,j] = y_tang\n",
                "    return xv_tang, yv_tang\n",
                "\n",
                "def plot_distortion(k1:float,k2:float,k3:float,k4:float,k5:float,k6:float, p1:float,p2:float) -> None:\n",
                "    \"\"\"Plots radial, tangential and compounded (radial + tangential) distortion grid. Using the Brown-Conrady model.\n",
                "\n",
                "    Args:\n",
                "        k1 (float): radial distortion coefficient\n",
                "        k2 (float): radial distortion coefficient\n",
                "        k3 (float): radial distortion coefficient\n",
                "        k4 (float): radial distortion coefficient\n",
                "        k5 (float): radial distortion coefficient\n",
                "        k6 (float): radial distortion coefficient\n",
                "        p1 (float): tangential distortion coefficient\n",
                "        p2 (float): tangential distortion coefficient\n",
                "    \"\"\"\n",
                "    k = (k1,k2,k3,k4,k5,k6)\n",
                "    p = (p1,p2)\n",
                "    squares = 10 # amount of squares in the grid\n",
                "    pts = 100\n",
                "    # realistical values for image with 2500 x 2500 pixels with focal length of 35mm which is close to 10500 pixels with basler camera pixel size, origin is in the center - therfore x and y should be within values +-(2500/10500)/2\n",
                "    width = 0.23\n",
                "    height = 0.23\n",
                "    xv, yv = np.meshgrid(np.linspace(-width/2,width/2,pts), np.linspace(-height/2,height/2,pts))\n",
                "\n",
                "    xv_radial, yv_radial = _radial_distortion(xv, yv, k)\n",
                "    xv_tang, yv_tang = _tangetial_distortion(xv, yv, p)\n",
                "\n",
                "    _, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
                "\n",
                "    _plot_grid(xv_radial, yv_radial, squares, axs[0])\n",
                "    axs[0].set_title('Radial distortion grid')\n",
                "\n",
                "    _plot_grid(xv_tang, yv_tang, squares, axs[1])\n",
                "    axs[1].set_title('Tangential distortion grid')\n",
                "\n",
                "    _plot_grid(xv_radial + xv_tang, yv_radial + yv_tang, squares, axs[2])\n",
                "    axs[2].set_title('Compounded distortion grid')\n",
                "    plt.show()\n"
            ],
            "id": "49f86ee587729df",
            "outputs": [],
            "execution_count": 1
        },
        {
            "metadata": {},
            "cell_type": "code",
            "outputs": [],
            "execution_count": null,
            "source": "",
            "id": "c53fe77aae21a168"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python [conda env:base] *",
            "language": "python",
            "name": "conda-base-py"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 2
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython2",
            "version": "2.7.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}